"""
ü§ñ CLAUDIA DA DESK - BOT CONVERSACIONAL SUPREMO üöÄ
Sistema de IA Conversacional de √öltima Gera√ß√£o - N√≠vel ChatGPT++
Processamento de Linguagem Natural Supremo para Portugu√™s Brasileiro
Intelig√™ncia Emocional, Mem√≥ria Contextual e Compreens√£o Sem√¢ntica Avan√ßada
"""
try:
    import torch
    import torch.nn as nn
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None
import json
import re
import pickle
import asyncio
from typing import Dict, List, Tuple, Optional, Any, Union
from datetime import datetime, timedelta
import numpy as np
import math
from dataclasses import dataclass
from collections import defaultdict, deque
try:
    from transformers import (
        AutoTokenizer, AutoModel, AutoModelForSequenceClassification,
        BertTokenizer, BertForSequenceClassification, pipeline,
        AutoModelForCausalLM, GPT2LMHeadModel
    )
    from sentence_transformers import SentenceTransformer
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    AutoTokenizer = None
    AutoModel = None
from backend.config.settings import active_config
from backend.utils.logger import conversation_logger, app_logger
from backend.models.conversation import ConversationContext

@dataclass
class EmotionalState:
    """Estado emocional detectado na conversa"""
    primary_emotion: str  # raiva, tristeza, alegria, medo, surpresa, nojo
    intensity: float  # 0.0 a 1.0
    confidence: float  # confian√ßa na detec√ß√£o
    indicators: List[str]  # palavras/frases que indicaram a emo√ß√£o
    timestamp: datetime

@dataclass
class ConversationMemory:
    """Mem√≥ria de conversa√ß√£o avan√ßada"""
    user_profile: Dict[str, Any]  # perfil do usu√°rio constru√≠do ao longo do tempo
    conversation_history: deque  # hist√≥rico limitado de mensagens
    emotional_timeline: List[EmotionalState]  # linha do tempo emocional
    key_facts: Dict[str, Any]  # fatos importantes sobre o usu√°rio
    preferences: Dict[str, Any]  # prefer√™ncias detectadas
    context_embeddings: np.ndarray  # embeddings para busca sem√¢ntica
    last_update: datetime

@dataclass
class SemanticUnderstanding:
    """Compreens√£o sem√¢ntica avan√ßada"""
    intent_confidence: float
    semantic_similarity: float
    contextual_relevance: float
    emotional_alignment: float
    topic_coherence: float

class EmotionalIntelligence:
    """Sistema de Intelig√™ncia Emocional Avan√ßado"""
    
    def __init__(self):
        # Mapeamento de palavras para emo√ß√µes
        self.emotion_lexicon = {
            "raiva": {
                "words": [
                    "raiva", "√≥dio", "irritado", "puto", "pissed", "furioso", 
                    "revoltado", "indignado", "zangado", "bravo", "nervoso",
                    "estressado", "saco cheio", "enchendo saco", "paci√™ncia",
                    "maldito", "droga", "merda", "inferno", "diabos"
                ],
                "phrases": [
                    "que raiva", "to puto", "saco cheio", "encheu o saco",
                    "perdi a paci√™ncia", "que merda", "vai se foder",
                    "to irritado", "me irrita", "que √≥dio"
                ]
            },
            "tristeza": {
                "words": [
                    "triste", "deprimido", "chateado", "desanimado", "down",
                    "melanc√≥lico", "cabisbaixo", "abatido", "chorar", "l√°grimas",
                    "perdido", "sozinho", "abandonado", "desesperado", "sem esperan√ßa"
                ],
                "phrases": [
                    "to triste", "me sinto mal", "que tristeza", "quero chorar",
                    "to down", "depre total", "sem √¢nimo", "vida dif√≠cil",
                    "que barra", "to mal"
                ]
            },
            "alegria": {
                "words": [
                    "feliz", "alegre", "contente", "satisfeito", "animado",
                    "euf√≥rico", "empolgado", "radiante", "sorrindo", "rindo",
                    "festa", "celebrar", "comemorar", "vit√≥ria", "sucesso"
                ],
                "phrases": [
                    "to feliz", "que alegria", "to animado", "muito bom",
                    "excelente", "perfeito", "show de bola", "massa",
                    "incr√≠vel", "sensacional"
                ]
            },
            "medo": {
                "words": [
                    "medo", "assustado", "nervoso", "ansioso", "preocupado",
                    "temeroso", "amedrontado", "inseguro", "receoso", "apreensivo",
                    "p√¢nico", "terror", "pavor", "susto", "ang√∫stia"
                ],
                "phrases": [
                    "to com medo", "preocupado", "ansioso", "nervoso",
                    "que vai acontecer", "e se", "tenho receio", "inseguro",
                    "com p√¢nico", "angustiado"
                ]
            },
            "surpresa": {
                "words": [
                    "surpreso", "espantado", "chocado", "impressionado", "uau",
                    "nossa", "caramba", "eita", "putz", "wow", "inacredit√°vel"
                ],
                "phrases": [
                    "que surpresa", "n√£o acredito", "s√©rio mesmo", "nossa senhora",
                    "caramba", "eita nossa", "que isso", "incr√≠vel"
                ]
            },
            "frustra√ß√£o": {
                "words": [
                    "frustrado", "cansado", "desistir", "largar", "chega",
                    "basta", "n√£o aguento", "saturado", "farto", "de saco cheio"
                ],
                "phrases": [
                    "to frustrado", "cansei", "desisto", "chega disso",
                    "n√£o aguento mais", "que saco", "j√° deu", "basta"
                ]
            }
        }
        
        # Intensificadores emocionais
        self.intensifiers = {
            "alto": ["muito", "super", "mega", "ultra", "extremamente", "totalmente"],
            "m√©dio": ["bem", "bastante", "meio", "um pouco"],
            "baixo": ["levemente", "ligeiramente", "pouco"]
        }
    
    def analyze_emotion(self, text: str) -> EmotionalState:
        """Analisa emo√ß√£o no texto com precis√£o avan√ßada"""
        text_lower = text.lower()
        detected_emotions = {}
        indicators = []
        
        # Analisa cada emo√ß√£o
        for emotion, patterns in self.emotion_lexicon.items():
            score = 0.0
            emotion_indicators = []
            
            # Verifica palavras-chave
            for word in patterns["words"]:
                if word in text_lower:
                    score += 1.0
                    emotion_indicators.append(word)
            
            # Verifica frases
            for phrase in patterns["phrases"]:
                if phrase in text_lower:
                    score += 2.0  # Frases t√™m peso maior
                    emotion_indicators.append(phrase)
            
            # Aplica intensificadores
            for intensity_level, words in self.intensifiers.items():
                for intensifier in words:
                    if intensifier in text_lower and emotion_indicators:
                        if intensity_level == "alto":
                            score *= 1.5
                        elif intensity_level == "m√©dio":
                            score *= 1.2
                        elif intensity_level == "baixo":
                            score *= 0.8
            
            if score > 0:
                detected_emotions[emotion] = {
                    "score": score,
                    "indicators": emotion_indicators
                }
                indicators.extend(emotion_indicators)
        
        # Determina emo√ß√£o principal
        if detected_emotions:
            primary_emotion = max(detected_emotions.keys(), 
                                key=lambda x: detected_emotions[x]["score"])
            max_score = detected_emotions[primary_emotion]["score"]
            
            # Normaliza intensidade (0.0 - 1.0)
            intensity = min(max_score / 5.0, 1.0)  # Max 5 pontos = intensidade 1.0
            confidence = min(intensity * 1.2, 1.0)  # Confian√ßa baseada na intensidade
            
            return EmotionalState(
                primary_emotion=primary_emotion,
                intensity=intensity,
                confidence=confidence,
                indicators=detected_emotions[primary_emotion]["indicators"],
                timestamp=datetime.now()
            )
        else:
            # Estado neutro
            return EmotionalState(
                primary_emotion="neutro",
                intensity=0.0,
                confidence=0.8,
                indicators=[],
                timestamp=datetime.now()
            )

class AdvancedMemorySystem:
    """Sistema de Mem√≥ria Conversacional Supremo"""
    
    def __init__(self, max_history: int = 50):
        self.max_history = max_history
        self.conversations: Dict[str, ConversationMemory] = {}
        
        # Modelo para embeddings sem√¢nticos
        if TRANSFORMERS_AVAILABLE:
            try:
                self.sentence_model = SentenceTransformer('neuralmind/bert-base-portuguese-cased')
            except:
                self.sentence_model = None
                app_logger.warning("SentenceTransformer n√£o dispon√≠vel, usando fallback")
        else:
            self.sentence_model = None
    
    def get_or_create_memory(self, user_id: str) -> ConversationMemory:
        """Obt√©m ou cria mem√≥ria para usu√°rio"""
        if user_id not in self.conversations:
            self.conversations[user_id] = ConversationMemory(
                user_profile={},
                conversation_history=deque(maxlen=self.max_history),
                emotional_timeline=[],
                key_facts={},
                preferences={},
                context_embeddings=np.array([]),
                last_update=datetime.now()
            )
        return self.conversations[user_id]
    
    def update_memory(
        self, 
        user_id: str, 
        message: str, 
        response: str, 
        emotional_state: EmotionalState,
        extracted_facts: Dict[str, Any]
    ):
        """Atualiza mem√≥ria do usu√°rio"""
        memory = self.get_or_create_memory(user_id)
        
        # Adiciona ao hist√≥rico
        memory.conversation_history.append({
            "timestamp": datetime.now(),
            "user_message": message,
            "bot_response": response,
            "emotion": emotional_state
        })
        
        # Atualiza linha do tempo emocional
        memory.emotional_timeline.append(emotional_state)
        
        # Mant√©m apenas √∫ltimas 20 emo√ß√µes
        if len(memory.emotional_timeline) > 20:
            memory.emotional_timeline = memory.emotional_timeline[-20:]
        
        # Atualiza fatos importantes
        memory.key_facts.update(extracted_facts)
        
        # Gera embeddings se dispon√≠vel
        if self.sentence_model:
            try:
                embedding = self.sentence_model.encode([message + " " + response])
                if memory.context_embeddings.size == 0:
                    memory.context_embeddings = embedding
                else:
                    # M√©dia dos embeddings (simplificado)
                    memory.context_embeddings = (memory.context_embeddings + embedding) / 2
            except Exception as e:
                app_logger.warning("Erro ao gerar embeddings", {"error": str(e)})
        
        memory.last_update = datetime.now()
    
    def get_contextual_information(self, user_id: str, current_message: str) -> Dict[str, Any]:
        """Obt√©m informa√ß√µes contextuais relevantes"""
        memory = self.get_or_create_memory(user_id)
        
        # An√°lise de padr√µes emocionais
        recent_emotions = memory.emotional_timeline[-5:] if memory.emotional_timeline else []
        emotional_pattern = self._analyze_emotional_pattern(recent_emotions)
        
        # Fatos relevantes
        relevant_facts = memory.key_facts
        
        # Hist√≥rico recente
        recent_history = list(memory.conversation_history)[-3:] if memory.conversation_history else []
        
        return {
            "emotional_pattern": emotional_pattern,
            "relevant_facts": relevant_facts,
            "recent_history": recent_history,
            "user_profile": memory.user_profile,
            "conversation_count": len(memory.conversation_history)
        }
    
    def _analyze_emotional_pattern(self, emotions: List[EmotionalState]) -> Dict[str, Any]:
        """Analisa padr√£o emocional do usu√°rio"""
        if not emotions:
            return {"trend": "neutral", "stability": "stable"}
        
        # Calcula tend√™ncia emocional
        emotion_values = {
            "alegria": 1.0, "surpresa": 0.5, "neutro": 0.0,
            "frustra√ß√£o": -0.3, "tristeza": -0.7, "raiva": -1.0, "medo": -0.5
        }
        
        values = [emotion_values.get(e.primary_emotion, 0.0) * e.intensity for e in emotions]
        
        if len(values) >= 2:
            trend = "improving" if values[-1] > values[0] else "declining" if values[-1] < values[0] else "stable"
        else:
            trend = "stable"
        
        # Calcula estabilidade
        variance = np.var(values) if len(values) > 1 else 0
        stability = "unstable" if variance > 0.3 else "moderate" if variance > 0.1 else "stable"
        
        return {
            "trend": trend,
            "stability": stability,
            "recent_emotion": emotions[-1].primary_emotion,
            "average_intensity": np.mean([e.intensity for e in emotions])
        }

class BillingContextEnforcer:
    """Garante 100% das respostas permane√ßam no contexto de cobran√ßas"""
    
    def __init__(self):
        self.billing_keywords = {
            'pagamento', 'boleto', 'fatura', 'conta', 'valor', 'd√≠vida', 'pix',
            'transfer√™ncia', 'cart√£o', 'cr√©dito', 'd√©bito', 'parcelamento',
            'desconto', 'negocia√ß√£o', 'vencimento', 'vencido', 'atraso',
            'juros', 'multa', 'acordo', 'quita√ß√£o', 'liquida√ß√£o', 'cobran√ßa'
        }
        
        self.billing_phrases = [
            "paguei a fatura", "enviei o comprovante", "quero parcelar",
            "preciso de desconto", "conta vencida", "valor incorreto",
            "n√£o reconhe√ßo esta cobran√ßa", "como fa√ßo para pagar",
            "qual √© o c√≥digo de barras", "posso negociar", "situa√ß√£o financeira"
        ]
        
        self.out_of_scope_responses = [
            "Desculpe, posso apenas ajudar com quest√µes relacionadas √† cobran√ßa e pagamento de faturas.",
            "Estou aqui exclusivamente para auxiliar com pagamentos, faturas e quest√µes financeiras.",
            "Por favor, limite sua pergunta a assuntos relacionados √† cobran√ßa e pagamento."
        ]
    
    def is_billing_related(self, text: str) -> tuple[bool, float]:
        """Verifica se o texto est√° relacionado a cobran√ßas"""
        text_lower = text.lower()
        
        # Conta palavras-chave de cobran√ßa
        keyword_count = sum(1 for keyword in self.billing_keywords 
                          if keyword in text_lower)
        
        # Verifica frases espec√≠ficas
        phrase_matches = sum(1 for phrase in self.billing_phrases 
                           if phrase in text_lower)
        
        # Calcula score de relev√¢ncia
        total_score = keyword_count + (phrase_matches * 2)
        confidence = min(total_score / 3.0, 1.0)
        
        return total_score > 0, confidence
    
    def enforce_billing_context(self, text: str, response: str) -> str:
        """Garante que a resposta permane√ßa no contexto de cobran√ßas"""
        is_related, _ = self.is_billing_related(text)
        
        if not is_related:
            return np.random.choice(self.out_of_scope_responses)
        
        return response

class AdvancedBillingNLP:
    """NLP avan√ßado especializado em cobran√ßas - n√≠vel ChatGPT++"""
    
    def __init__(self):
        # Inten√ß√µes espec√≠ficas de cobran√ßa
        self.billing_intents = {
            'payment_confirmation': {
                'patterns': [
                    r'paguei\s+(?:a|o)\s+(?:fatura|conta|boleto)',
                    r'(?:j√°|acabei de)\s+pagar',
                    r'enviei\s+(?:o|meu)\s+comprovante',
                    r'(?:fiz|realizei)\s+(?:o|um)\s+pagamento',
                    r'(?:pago|quitado|liquidado)'
                ],
                'confidence_threshold': 0.85
            },
            'payment_request': {
                'patterns': [
                    r'(?:como|onde)\s+posso\s+pagar',
                    r'(?:qual √©|me diga)\s+o\s+c√≥digo\s+de\s+barras',
                    r'(?:preciso|quero)\s+pagar',
                    r'(?:informa√ß√µes|dados)\s+para\s+pagamento',
                    r'(?:link|site|app)\s+para\s+pagar'
                ],
                'confidence_threshold': 0.80
            },
            'negotiation_request': {
                'patterns': [
                    r'(?:posso|d√° para)\s+negociar',
                    r'(?:preciso|quero)\s+de\s+desconto',
                    r'(?:parcelar|dividir)\s+(?:o|em)\s+vezes',
                    r'(?:situa√ß√£o|problema)\s+financeir[ao]',
                    r'(?:desempregado|sem renda|dificuldade)'
                ],
                'confidence_threshold': 0.75
            },
            'dispute_charge': {
                'patterns': [
                    r'(?:n√£o reconhe√ßo|n√£o lembro|n√£o comprei)',
                    r'(?:conta|valor)\s+incorreto',
                    r'(?:erro|engano)\s+na\s+cobran√ßa',
                    r'(?:golpe|fraude|indevido)',
                    r'(?:cancelar|reverter)\s+pagamento'
                ],
                'confidence_threshold': 0.80
            }
        }
        
        # Entidades financeiras
        self.financial_entities = {
            'amount': [
                r'(?:R\$|RS|R)\s*\d+(?:[,.]\d{2})?',
                r'\d+(?:[,.]\d{2})?\s*(?:reais|real|centavos)',
                r'(?:total|valor|pre√ßo)\s+(?:de\s+)?\d+(?:[,.]\d{2})?'
            ],
            'date': [
                r'\d{2}/\d{2}/\d{4}',
                r'\d{2}/\d{2}',
                r'(?:vencimento|vence)\s+(?:dia\s+)?\d{1,2}',
                r'(?:ontem|hoje|amanh√£|pr√≥xima semana)'
            ],
            'payment_method': [
                r'(?:pix|boleto|cart√£o|transfer√™ncia|d√©bito|cr√©dito)',
                r'(?:d√©bito autom√°tico|d√©bito em conta)',
                r'(?:TED|DOC|DOC/TED)'
            ],
            'account_number': [
                r'(?:n√∫mero|codigo)\s+(?:da\s+)?(?:conta|fatura)',
                r'(?:ref|refer√™ncia)\s*[.:]\s*\d+',
                r'(?:nosso\s+)?n√∫mero\s*[.:]\s*\d+'
            ]
        }
    
    def extract_billing_intent(self, text: str) -> Dict[str, Any]:
        """Extrai inten√ß√£o espec√≠fica de cobran√ßa com alta precis√£o"""
        text_lower = text.lower()
        results = {}
        
        for intent_name, intent_data in self.billing_intents.items():
            max_confidence = 0.0
            matched_pattern = None
            
            for pattern in intent_data['patterns']:
                match = re.search(pattern, text_lower)
                if match:
                    # Calcula confian√ßa baseada no tamanho do match
                    confidence = len(match.group()) / len(text_lower)
                    if confidence > max_confidence:
                        max_confidence = confidence
                        matched_pattern = pattern
            
            if max_confidence >= intent_data['confidence_threshold']:
                results[intent_name] = {
                    'confidence': max_confidence,
                    'pattern': matched_pattern,
                    'text_match': re.search(matched_pattern, text_lower).group() if matched_pattern else None
                }
        
        return results
    
    def extract_financial_entities(self, text: str) -> Dict[str, List[str]]:
        """Extrai entidades financeiras do texto"""
        entities = {}
        text_lower = text.lower()
        
        for entity_type, patterns in self.financial_entities.items():
            matches = []
            for pattern in patterns:
                found = re.findall(pattern, text_lower)
                matches.extend(found)
            
            if matches:
                entities[entity_type] = matches
        
        return entities
    
    def analyze_financial_sentiment(self, text: str) -> Dict[str, float]:
        """Analisa sentimento espec√≠fico para contexto financeiro"""
        text_lower = text.lower()
        
        positive_indicators = [
            'pago', 'quitado', 'liquidado', 'resolvido', 'tudo certo',
            'obrigado', 'agrade√ßo', 'excelente', '√≥timo', 'perfeito'
        ]
        
        negative_indicators = [
            'problema', 'erro', 'golpe', 'fraude', 'incorreto', 'indevido',
            'dif√≠cil', 'imposs√≠vel', 'desempregado', 'sem dinheiro', 'quebrado'
        ]
        
        urgency_indicators = [
            'urgente', 'r√°pido', 'imediatamente', 'preciso', 'necess√°rio',
            'agora', 'hoje', 'amanh√£', 'prazo', 'vencimento'
        ]
        
        positive_score = sum(1 for indicator in positive_indicators if indicator in text_lower)
        negative_score = sum(1 for indicator in negative_indicators if indicator in text_lower)
        urgency_score = sum(1 for indicator in urgency_indicators if indicator in text_lower)
        
        total_words = len(text_lower.split())
        
        return {
            'positive': positive_score / max(total_words, 1),
            'negative': negative_score / max(total_words, 1),
            'urgency': urgency_score / max(total_words, 1),
            'overall': (positive_score - negative_score) / max(total_words, 1)
        }

class BrazilianTextNormalizer:
    """Normalizador supremo de texto brasileiro coloquial - otimizado para cobran√ßas"""
    
    def __init__(self):
        # Mapeamento de abrevia√ß√µes e g√≠rias para portugu√™s formal - focado em termos financeiros
        self.abbreviations = {
            # Internet slang
            "vc": "voc√™", "vcs": "voc√™s", "q": "que", "qq": "qualquer",
            "tb": "tamb√©m", "tbm": "tamb√©m", "td": "tudo", "mto": "muito",
            "mt": "muito", "msm": "mesmo", "dps": "depois", "blz": "beleza",
            "vlw": "valeu", "obg": "obrigado", "pq": "porque", "pq√™": "porque",
            
            # Abrevia√ß√µes de tempo
            "hj": "hoje", "onti": "ontem", "amanha": "amanh√£", "sema": "semana",
            "mes": "m√™s", "ano": "ano", "hr": "hora", "min": "minuto",
            
            # Abrevia√ß√µes financeiras especializadas
            "dinherio": "dinheiro", "bufunfa": "dinheiro", "grana": "dinheiro",
            "pixe": "pix", "pixi": "pix", "conta": "conta", "fat": "fatura",
            "bol": "boleto", "transf": "transfer√™ncia", "cart": "cart√£o",
            "parc": "parcelamento", "desc": "desconto", "neg": "negocia√ß√£o",
            "venc": "vencimento", "atras": "atraso", "jur": "juros",
            "mult": "multa", "quit": "quitado", "liq": "liquidado",
            
            # Erros comuns de digita√ß√£o financeira
            "nao": "n√£o", "tah": "est√°", "tao": "t√£o", "eh": "√©",
            "pra": "para", "pro": "para", "pros": "para", "pras": "para",
            "ta": "est√°", "to": "estou", "tava": "estava",
            "paguei": "paguei", "paguie": "paguei", "pagiei": "paguei",
            "pagar": "pagar", "pague": "pague", "pagando": "pagando",
            
            # G√≠rias financeiras
            "trampo": "trabalho", "role": "situa√ß√£o", "parada": "situa√ß√£o",
            "bagulho": "coisa", "tro√ßo": "coisa", "neg√≥cio": "coisa",
            "liso": "sem dinheiro", "quebrado": "sem recursos financeiros",
            "quebrado": "em dificuldade financeira", "falido": "sem condi√ß√µes de pagar",
            
            # Cumprimentos abreviados
            "bd": "bom dia", "bt": "boa tarde", "bn": "boa noite",
            "eae": "e a√≠", "blz": "beleza", "tmj": "estamos juntos",
            "flw": "falou", "vlws": "valeu", "obrigado": "obrigado"
        }
        
        # Corre√ß√µes de erros comuns
        self.spelling_corrections = {
            "paguie": "paguei", "pagiei": "paguei", "baguei": "paguei",
            "fis": "fiz", "fes": "fez", "seii": "sei", "intendi": "entendi",
            "esplica": "explica", "difisil": "dif√≠cil", "facil": "f√°cil",
            "seman": "semana", "seista": "sexta", "sesta": "sexta",
            "qunto": "quanto", "qnto": "quanto", "ond": "onde",
            "brigadu": "obrigado", "falow": "falou", "ati": "at√©",
            "difficuldades": "dificuldades", "negosiar": "negociar"
        }
        
        # Remo√ß√£o de caracteres repetidos
        self.repeated_chars = re.compile(r'(.)\1{2,}')
    
    def normalize(self, text: str) -> str:
        """Normaliza texto coloquial brasileiro"""
        if not text:
            return ""
        
        # Converte para min√∫sculo
        normalized = text.lower().strip()
        
        # Remove caracteres especiais desnecess√°rios
        normalized = re.sub(r'[^\w\s\-.,!?√°√©√≠√≥√∫√¢√™√Æ√¥√ª√£√µ√ß]', '', normalized)
        
        # Corrige caracteres repetidos (ex: "oiiiii" -> "oi")
        normalized = self.repeated_chars.sub(r'\1\1', normalized)
        
        # Aplica corre√ß√µes ortogr√°ficas
        words = normalized.split()
        corrected_words = []
        
        for word in words:
            # Remove pontua√ß√£o para compara√ß√£o
            clean_word = re.sub(r'[.,!?]', '', word)
            
            # Verifica corre√ß√µes espec√≠ficas
            if clean_word in self.spelling_corrections:
                corrected_word = self.spelling_corrections[clean_word]
                # Preserva pontua√ß√£o
                if word != clean_word:
                    corrected_word += word[len(clean_word):]
                corrected_words.append(corrected_word)
            # Verifica abrevia√ß√µes
            elif clean_word in self.abbreviations:
                corrected_word = self.abbreviations[clean_word]
                # Preserva pontua√ß√£o
                if word != clean_word:
                    corrected_word += word[len(clean_word):]
                corrected_words.append(corrected_word)
            else:
                corrected_words.append(word)
        
        return ' '.join(corrected_words)
    
    def extract_intent_signals(self, text: str) -> List[str]:
        """Extrai sinais de inten√ß√£o do texto"""
        signals = []
        text_lower = text.lower()
        
        # Sinais de confirma√ß√£o de pagamento
        payment_signals = [
            "paguei", "pix", "transferi", "boleto", "depositei",
            "j√° foi", "j√° era", "mandei", "enviei"
        ]
        
        # Sinais de negocia√ß√£o
        negotiation_signals = [
            "parcelar", "desconto", "acordo", "dif√≠cil", "sem dinheiro",
            "desempregado", "quebrado", "liso", "condi√ß√µes"
        ]
        
        # Sinais de contesta√ß√£o
        dispute_signals = [
            "erro", "engano", "n√£o devo", "n√£o reconhe√ßo", "golpe",
            "nunca", "n√£o fui eu"
        ]
        
        for signal in payment_signals:
            if signal in text_lower:
                signals.append("payment_confirmed")
                break
        
        for signal in negotiation_signals:
            if signal in text_lower:
                signals.append("wants_negotiation")
                break
        
        for signal in dispute_signals:
            if signal in text_lower:
                signals.append("disputes_charge")
                break
        
        return signals

class SpellCorrector:
    """Corretor ortogr√°fico especializado em portugu√™s brasileiro coloquial"""
    
    def __init__(self):
        # Dist√¢ncia de Levenshtein para palavras similares
        self.common_words = {
            "pagamento", "dinheiro", "valor", "conta", "banco", "pix",
            "transfer√™ncia", "boleto", "d√©bito", "cr√©dito", "cart√£o",
            "parcelar", "desconto", "acordo", "negociar", "prazo"
        }
        
        # Corre√ß√µes fon√©ticas (como as pessoas escrevem vs como deveria ser)
        self.phonetic_corrections = {
            "ki": "qui", "ke": "que", "ka": "ca", "ko": "co",
            "ks": "x", "s": "√ß", "ss": "√ß"
        }
    
    def correct_word(self, word: str) -> str:
        """Corrige uma palavra usando similaridade fon√©tica"""
        if len(word) < 3:
            return word
        
        best_match = word
        min_distance = float('inf')
        
        for correct_word in self.common_words:
            distance = self._levenshtein_distance(word.lower(), correct_word.lower())
            if distance < min_distance and distance <= 2:  # M√°ximo 2 erros
                min_distance = distance
                best_match = correct_word
        
        return best_match if min_distance <= 2 else word
    
    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """Calcula dist√¢ncia de Levenshtein entre duas strings"""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]

class ConversationLearning:
    """Sistema de Aprendizado Cont√≠nuo"""
    
    def __init__(self):
        self.interaction_patterns = defaultdict(list)
        self.success_metrics = defaultdict(float)
        self.failure_patterns = defaultdict(list)


class AdvancedBillingNLP:
    """NLP avan√ßado nivel ChatGPT para cobran√ßas e faturas"""
    
    def __init__(self):
        # Contexto e mem√≥ria de conversa√ß√£o
        self.conversation_memory = {}
        self.context_stack = []
        
        # Inten√ß√µes refinadas com contexto emocional
        self.intent_contexts = {
            'urgent_payment': {
                'patterns': [
                    r'\b(urgente|imediato|r√°pido|hoje|agora|j√°)\s+(pagar|resolver|quitar)\b',
                    r'\b(vence\s+(hoje|amanh√£|em\s+breve))\b.*\b(preciso|quero)\b',
                    r'\b(evitar|n√£o\s+quero)\s+(multa|juros|atraso)\b'
                ],
                'context': {'urgency': 1.0, 'anxiety': 0.8, 'cooperation': 0.6},
                'responses': ['entendo_urgencia', 'oferecer_solucao_rapida']
            },
            'empathetic_negotiation': {
                'patterns': [
                    r'\b(n√£o\s+tenho|sem\s+condi√ß√µes|dificuldade|crise)\s+(dinheiro|condi√ß√µes)\b',
                    r'\b(perdi\s+emprego|sal√°rio\s+reduzido|problema\s+financeiro)\b',
                    r'\b(posso\s+pagar\s+entrada\s+baixa|parcelar\s+em\s+muitas)\b'
                ],
                'context': {'empathy': 1.0, 'flexibility': 0.9, 'support': 0.8},
                'responses': ['demonstrar_empatia', 'oferecer_flexibilidade']
            },
            'detailed_dispute': {
                'patterns': [
                    r'\b(n√£o\s+reconhe√ßo|n√£o\s+fez|n√£o\s+comprei)\s+(essa|esta)\s+(compra|cobran√ßa)\b',
                    r'\b(contesto|questiono)\s+(motivo|raz√£o)\s+.*\b(erro|fraude|golpe)\b',
                    r'\b(preciso\s+de)\s+(prova|comprovante|evid√™ncia)\b'
                ],
                'context': {'investigation': 1.0, 'documentation': 0.9, 'patience': 0.7},
                'responses': ['investigar_detalhadamente', 'solicitar_documentacao']
            },
            'proactive_payment': {
                'patterns': [
                    r'\b(quero|vou|pretendo)\s+(pagar|quitar|resolver)\s+(hoje|agora|imediatamente)\b',
                    r'\b(como\s+posso)\s+(gerar|emitir)\s+(boleto|pix)\b',
                    r'\b(consigo\s+pagar|tenho\s+condi√ß√µes)\s+(√†\s+vista|parcelado)\b'
                ],
                'context': {'proactivity': 1.0, 'efficiency': 0.9, 'appreciation': 0.8},
                'responses': ['facilitar_processo', 'agradecer_proatividade']
            }
        }
        
        # Entidades financeiras com valida√ß√£o inteligente
        self.smart_entities = {
            'dynamic_amount': {
                'patterns': [
                    r'\b(total|valor|d√≠vida|saldo)\s+(?:de\s+)?R\$\s*(\d+(?:\.\d{3})*(?:,\d{2})?)\b',
                    r'\b(\d+(?:\.\d{3})*(?:,\d{2})?)\s*(?:reais|R\$)\s+(?:de|em)\s+(?:d√≠vida|d√©bito)\b',
                    r'\b(?:est√°|fica\s+em)\s+R\$\s*(\d+(?:\.\d{3})*(?:,\d{2})?)\b'
                ],
                'validators': ['is_valid_brazilian_currency'],
                'normalizers': ['format_brl_currency']
            },
            'contextual_date': {
                'patterns': [
                    r'\b(vence|vencimento|prazo)\s+(?:em|dia)\s+(\d{1,2}(?:\/\d{1,2}(?:\/\d{2,4})?)?)\b',
                    r'\b(\d{1,2}\s+de\s+\w+(?:\s+de\s+\d{2,4})?)\s+(?:vence|vencimento)\b',
                    r'\b(?:pr√≥xima?|pr√≥ximo)\s+(?:data|dia)\s+(?:vencimento|pagamento)\b'
                ],
                'validators': ['is_valid_date', 'is_future_date'],
                'normalizers': ['format_iso_date', 'add_year_context']
            },
            'payment_preference': {
                'patterns': [
                    r'\b(prefiro|quero|gostaria)\s+(?:de\s+)?(pix|boleto|cart√£o|transfer√™ncia)\b',
                    r'\b(?:via|por)\s+(pix|boleto|cart√£o\s+(?:de\s+)?(?:cr√©dito|d√©bito))\b',
                    r'\b(aceita|aceitam)\s+(pix|boleto|cart√£o)\b'
                ],
                'validators': ['is_valid_payment_method'],
                'normalizers': ['standardize_payment_method']
            }
        }
        
        # An√°lise emocional avan√ßada
        self.emotional_intelligence = {
            'sentiment_layers': {
                'surface_emotion': {
                    'positive': ['obrigado', 'valeu', '√≥timo', 'excelente', 'resolvido', 'perfeito'],
                    'negative': ['ruim', 'p√©ssimo', 'horr√≠vel', 'terr√≠vel', 'pior'],
                    'neutral': ['ok', 'entendo', 'certo', 'tudo bem', 'normal']
                },
                'deep_emotion': {
                    'anxiety': ['preocupado', 'ansioso', 'medo', 'desesperado', 'nervoso', 'stress'],
                    'frustration': ['frustrado', 'irritado', 'chateado', 'insatisfeito', 'decepcionado'],
                    'hope': ['esperan√ßa', 'confiante', 'determinado', 'motivado', 'positivo'],
                    'despair': ['desesperan√ßa', 'derrotado', 'sem sa√≠da', 'acabado', 'desistir']
                },
                'behavioral_cues': {
                    'cooperative': ['entendo', 'quero resolver', 'posso', 'vou tentar', 'aceito', 'concordo'],
                    'resistant': ['n√£o', 'imposs√≠vel', 'inaceit√°vel', 'injusto', 'jamais', 'recuso'],
                    'confused': ['n√£o entendo', 'como assim', 'n√£o sei', 'me explica', 'n√£o compreendo']
                }
            },
            'intensity_markers': {
                'high': ['muito', 'extremamente', 'absolutamente', 'totalmente', 'completamente'],
                'medium': ['bastante', 'razoavelmente', 'relativamente', 'moderadamente'],
                'low': ['um pouco', 'meio', 'ligeiramente', 'minimamente']
            }
        }

    def extract_billing_intent(self, text: str, user_id: str = None, context: Dict = None) -> Dict[str, Any]:
        """Extrai inten√ß√£o com contexto de conversa√ß√£o e mem√≥ria"""
        text_lower = text.lower().strip()
        
        # Contexto da conversa√ß√£o atual
        conversation_context = self._get_conversation_context(user_id)
        
        # An√°lise de inten√ß√£o contextual
        best_intent = None
        max_confidence = 0.0
        
        for intent_name, intent_data in self.intent_contexts.items():
            for pattern in intent_data['patterns']:
                match = re.search(pattern, text_lower, re.IGNORECASE)
                if match:
                    # Calcula confian√ßa com contexto
                    base_confidence = 0.75
                    
                    # Boost baseado em contexto anterior
                    context_boost = self._calculate_context_boost(
                        intent_name, conversation_context
                    )
                    
                    # Boost baseado em urg√™ncia/emotion
                    emotion_boost = self._calculate_emotion_boost(text_lower)
                    
                    confidence = min(base_confidence + context_boost + emotion_boost, 1.0)
                    
                    if confidence > max_confidence:
                        max_confidence = confidence
                        best_intent = {
                            'intent': intent_name,
                            'confidence': confidence,
                            'context': intent_data['context'],
                            'match': match.group(),
                            'timestamp': datetime.now().isoformat(),
                            'conversation_context': conversation_context
                        }
        
        # Fallback inteligente com IA
        if not best_intent:
            best_intent = self._intelligent_fallback(text_lower, conversation_context)
        
        # Atualiza mem√≥ria de conversa√ß√£o
        if user_id:
            self._update_conversation_memory(user_id, best_intent)
        
        return best_intent

    def extract_financial_entities(self, text: str, context: Dict = None) -> Dict[str, List[str]]:
        """Extrai entidades com valida√ß√£o e contexto inteligente"""
        entities = {}
        text_lower = text.lower().strip()
        
        for entity_name, entity_config in self.smart_entities.items():
            entities[entity_name] = []
            
            for pattern in entity_config['patterns']:
                matches = re.findall(pattern, text_lower, re.IGNORECASE)
                
                for match in matches:
                    if isinstance(match, tuple):
                        # Extrai o grupo correto
                        for group in match:
                            if group and not group.lower() in ['total', 'valor', 'de', 'em']:
                                normalized = self._normalize_entity(
                                    entity_name, group.strip()
                                )
                                if normalized and self._validate_entity(entity_name, normalized):
                                    entities[entity_name].append(normalized)
                                    break
                    else:
                        normalized = self._normalize_entity(entity_name, str(match).strip())
                        if normalized and self._validate_entity(entity_name, normalized):
                            entities[entity_name].append(normalized)
            
            # Remove duplicatas e ordena por relev√¢ncia
            entities[entity_name] = list(dict.fromkeys(entities[entity_name]))
        
        # An√°lise contextual de entidades
        entities = self._contextual_entity_analysis(entities, context)
        
        return entities

    def analyze_financial_sentiment(self, text: str, user_id: str = None) -> Dict[str, Any]:
        """An√°lise emocional profunda n√≠vel ChatGPT"""
        text_lower = text.lower().strip()
        words = text_lower.split()
        
        # An√°lise multicamadas
        analysis = {
            'surface_sentiment': self._analyze_surface_sentiment(words),
            'deep_emotion': self._analyze_deep_emotion(text_lower),
            'behavioral_analysis': self._analyze_behavioral_patterns(text_lower),
            'intensity_analysis': self._analyze_intensity(text_lower),
            'temporal_emotion': self._analyze_temporal_emotion(user_id, text_lower)
        }
        
        # Score geral de sentimento
        overall_score = self._calculate_comprehensive_sentiment(analysis)
        analysis['overall'] = overall_score
        
        # Insights e recomenda√ß√µes
        analysis['insights'] = self._generate_emotional_insights(analysis)
        
        return analysis

    def _get_conversation_context(self, user_id: str) -> Dict:
        """Recupera contexto de conversa√ß√£o"""
        if not user_id:
            return {}
        
        return self.conversation_memory.get(user_id, {
            'last_intent': None,
            'emotional_state': 'neutral',
            'entities_extracted': [],
            'interaction_count': 0
        })

    def _calculate_context_boost(self, intent: str, context: Dict) -> float:
        """Calcula boost baseado em contexto de conversa√ß√£o"""
        boost = 0.0
        
        # Se o usu√°rio est√° seguindo uma linha de racioc√≠nio
        if context.get('last_intent') == intent:
            boost += 0.15
        
        # Se h√° entidades relevantes no contexto
        if context.get('entities_extracted'):
            boost += 0.1
        
        return boost

    def _calculate_emotion_boost(self, text: str) -> float:
        """Calcula boost baseado em intensidade emocional"""
        emotion_words = {
            'urgent': ['urgente', 'imediatamente', 'agora', 'j√°', 'r√°pido'],
            'anxious': ['preocupado', 'desesperado', 'medo', 'ansioso'],
            'angry': ['raiva', 'bravo', 'irritado', 'furioso', 'odio']
        }
        
        boost = 0.0
        for category, words in emotion_words.items():
            if any(word in text for word in words):
                boost += 0.1
        
        return boost

    def _intelligent_fallback(self, text: str, context: Dict) -> Dict[str, Any]:
        """Fallback inteligente quando nenhuma inten√ß√£o espec√≠fica √© detectada"""
        # An√°lise sem√¢ntica geral
        billing_indicators = [
            'fatura', 'conta', 'd√©bito', 'cobran√ßa', 'pagamento', 'valor', 'vencimento',
            'boleto', 'pix', 'cart√£o', 'saldo', 'd√≠vida'
        ]
        
        indicator_count = sum(1 for indicator in billing_indicators if indicator in text)
        
        if indicator_count >= 2:
            return {
                'intent': 'billing_inquiry',
                'confidence': 0.6 + (indicator_count * 0.1),
                'context': {'general_billing': True, 'indicators': indicator_count},
                'match': f'billing_context_{indicator_count}',
                'timestamp': datetime.now().isoformat(),
                'conversation_context': context
            }
        
        return {
            'intent': 'clarification_needed',
            'confidence': 0.4,
            'context': {'unclear': True},
            'match': None,
            'timestamp': datetime.now().isoformat(),
            'conversation_context': context
        }

    def _update_conversation_memory(self, user_id: str, intent_data: Dict):
        """Atualiza mem√≥ria de conversa√ß√£o"""
        if not user_id:
            return
        
        if user_id not in self.conversation_memory:
            self.conversation_memory[user_id] = {
                'last_intent': None,
                'emotional_state': 'neutral',
                'entities_extracted': [],
                'interaction_count': 0,
                'conversation_history': []
            }
        
        self.conversation_memory[user_id]['last_intent'] = intent_data['intent']
        self.conversation_memory[user_id]['interaction_count'] += 1
        self.conversation_memory[user_id]['conversation_history'].append({
            'timestamp': intent_data['timestamp'],
            'intent': intent_data['intent'],
            'confidence': intent_data['confidence']
        })

    def _normalize_entity(self, entity_type: str, value: str) -> Optional[str]:
        """Normaliza entidades com base no tipo"""
        if not value:
            return None
        
        value = str(value).strip()
        
        if entity_type == 'dynamic_amount':
            # Remove caracteres n√£o num√©ricos e formata como moeda
            clean_value = re.sub(r'[^\d,]', '', value)
            if clean_value:
                return f"R$ {clean_value}"
        
        elif entity_type == 'contextual_date':
            # Normaliza datas para formato ISO
            return self._normalize_date(value)
        
        elif entity_type == 'payment_preference':
            # Padroniza m√©todos de pagamento
            return value.lower().replace(' ', '_')
        
        return value

    def _validate_entity(self, entity_type: str, value: str) -> bool:
        """Valida entidades com base em regras espec√≠ficas"""
        if not value:
            return False
        
        if entity_type == 'dynamic_amount':
            # Valida formato de moeda brasileira
            amount_match = re.search(r'\d+(?:[.,]\d{2})?', value)
            return amount_match is not None
        
        elif entity_type == 'contextual_date':
            # Valida se √© uma data v√°lida
            return self._is_valid_date(value)
        
        return True

    def _contextual_entity_analysis(self, entities: Dict[str, List[str]], context: Dict = None) -> Dict[str, List[str]]:
        """An√°lise contextual das entidades extra√≠das"""
        if not context:
            return entities
        
        # Prioriza entidades relevantes ao contexto
        prioritized = {}
        
        for entity_type, values in entities.items():
            if values:
                # Ordena por relev√¢ncia ao contexto
                prioritized[entity_type] = sorted(values, key=lambda x: self._relevance_score(x, context), reverse=True)[:3]
        
        return prioritized

    def _analyze_surface_sentiment(self, words: List[str]) -> Dict[str, float]:
        """An√°lise de sentimento superficial"""
        surface_layer = self.emotional_intelligence['sentiment_layers']['surface_emotion']
        
        scores = {}
        for category, keywords in surface_layer.items():
            score = sum(1 for word in words if word.lower() in keywords)
            scores[category] = score / max(len(words), 1)
        
        return scores

    def _analyze_deep_emotion(self, text: str) -> Dict[str, float]:
        """An√°lise de emo√ß√µes profundas"""
        deep_layer = self.emotional_intelligence['sentiment_layers']['deep_emotion']
        
        scores = {}
        for emotion, keywords in deep_layer.items():
            score = sum(1 for keyword in keywords if keyword in text)
            scores[emotion] = score / len(keywords)
        
        return scores

    def _analyze_behavioral_patterns(self, text: str) -> Dict[str, float]:
        """An√°lise de padr√µes comportamentais"""
        behavioral_layer = self.emotional_intelligence['sentiment_layers']['behavioral_cues']
        
        scores = {}
        for pattern, keywords in behavioral_layer.items():
            score = sum(1 for keyword in keywords if keyword in text)
            scores[pattern] = score / len(keywords)
        
        return scores

    def _analyze_intensity(self, text: str) -> Dict[str, float]:
        """An√°lise de intensidade emocional"""
        intensity_markers = self.emotional_intelligence['intensity_markers']
        
        scores = {}
        for level, markers in intensity_markers.items():
            score = sum(1 for marker in markers if marker in text)
            scores[level] = score / len(markers)
        
        return scores

    def _analyze_temporal_emotion(self, user_id: str, text: str) -> Dict[str, Any]:
        """An√°lise temporal de emo√ß√£o ao longo da conversa"""
        if not user_id or user_id not in self.conversation_memory:
            return {'trend': 'neutral', 'consistency': 0.0}
        
        history = self.conversation_memory[user_id]['conversation_history']
        if len(history) < 2:
            return {'trend': 'neutral', 'consistency': 0.0}
        
        # Analisa tend√™ncia emocional
        recent_emotions = []
        for interaction in history[-5:]:
            # Extrai emo√ß√£o da intera√ß√£o (simplificado)
            emotion = 'neutral'  # Seria mais sofisticado em produ√ß√£o
            recent_emotions.append(emotion)
        
        return {
            'trend': self._calculate_emotion_trend(recent_emotions),
            'consistency': self._calculate_consistency(recent_emotions),
            'volatility': self._calculate_volatility(recent_emotions)
        }

    def _calculate_comprehensive_sentiment(self, analysis: Dict[str, Any]) -> Dict[str, float]:
        """Calcula sentimento geral baseado em todas as camadas"""
        weights = {
            'surface_sentiment': 0.2,
            'deep_emotion': 0.3,
            'behavioral_analysis': 0.3,
            'intensity_analysis': 0.2
        }
        
        total_score = 0.0
        for layer, weight in weights.items():
            if layer in analysis:
                layer_data = analysis[layer]
                if isinstance(layer_data, dict):
                    # Converte para score num√©rico
                    positive = layer_data.get('positive', 0)
                    negative = layer_data.get('negative', 0)
                    score = (positive - negative) / max(len(layer_data), 1)
                    total_score += score * weight
        
        return {
            'score': total_score,
            'confidence': min(0.95, len(analysis) / 4.0),
            'interpretation': self._interpret_sentiment_score(total_score),
            'severity': self._calculate_severity(total_score)
        }

    def _interpret_sentiment_score(self, score: float) -> str:
        """Interpreta o score de sentimento"""
        if score > 0.5:
            return 'very_positive'
        elif score > 0.1:
            return 'positive'
        elif score < -0.5:
            return 'very_negative'
        elif score < -0.1:
            return 'negative'
        else:
            return 'neutral'

    def _calculate_severity(self, score: float) -> str:
        """Calcula severidade do sentimento"""
        abs_score = abs(score)
        if abs_score > 0.8:
            return 'critical'
        elif abs_score > 0.5:
            return 'high'
        elif abs_score > 0.2:
            return 'medium'
        else:
            return 'low'

    def _generate_emotional_insights(self, analysis: Dict[str, Any]) -> Dict[str, str]:
        """Gera insights e recomenda√ß√µes baseadas em an√°lise emocional"""
        insights = {}
        
        overall = analysis.get('overall', {})
        interpretation = overall.get('interpretation', 'neutral')
        severity = overall.get('severity', 'low')
        
        if interpretation in ['very_negative', 'negative']:
            insights['approach'] = 'empathetic'
            insights['tone'] = 'supportive'
            insights['priority'] = 'high'
        elif interpretation in ['positive', 'very_positive']:
            insights['approach'] = 'efficient'
            insights['tone'] = 'appreciative'
            insights['priority'] = 'medium'
        else:
            insights['approach'] = 'informative'
            insights['tone'] = 'professional'
            insights['priority'] = 'normal'
        
        return insights


class BillingContextEnforcer:
    """Garante que todas as respostas permane√ßam no escopo de cobran√ßas e faturas"""
    
    def __init__(self):
        self.billing_keywords = [
            'pagamento', 'cobran√ßa', 'fatura', 'boleto', 'pix', 'transfer√™ncia',
            'd√≠vida', 'valor', 'vencimento', 'parcela', 'desconto', 'juros',
            'multa', 'negocia√ß√£o', 'acordo', 'quitado', 'liquidado', 'saldo',
            'conta', 'banc√°rio', 'financeiro', 'cart√£o', 'cr√©dito', 'd√©bito'
        ]
        
        self.out_of_scope_responses = [
            "Desculpe, mas s√≥ posso ajudar com quest√µes relacionadas a cobran√ßas e faturas.",
            "Entendo sua quest√£o, mas meu foco √© exclusivamente em cobran√ßas e pagamentos.",
            "S√≥ trabalho com assuntos financeiros e cobran√ßas. Posso ajudar com sua conta?",
            "Infelizmente, s√≥ posso auxiliar com quest√µes de cobran√ßa e faturas.",
            "Meu escopo √© exclusivamente cobran√ßas. Como posso ajudar com sua situa√ß√£o financeira?"
        ]
    
    def is_billing_related(self, text: str) -> bool:
        """Verifica se o texto est√° relacionado a cobran√ßas"""
        text_lower = text.lower()
        
        # Verifica palavras-chave de cobran√ßa
        for keyword in self.billing_keywords:
            if keyword in text_lower:
                return True
        
        # Verifica padr√µes financeiros
        financial_patterns = [
            r'R\$\s*\d',
            r'\d+\s*reais?',
            r'\b\d+[\/\-]\d+[\/\-]\d+\b',  # Datas
            r'\b(pix|boleto|ted|doc)\b'
        ]
        
        for pattern in financial_patterns:
            if re.search(pattern, text_lower):
                return True
        
        return False
    
    def get_out_of_scope_response(self) -> str:
        """Retorna resposta padr√£o para t√≥picos fora do escopo"""
        return random.choice(self.out_of_scope_responses)
    
    def enforce_billing_context(self, user_message: str, proposed_response: str) -> str:
        """Garante que a resposta permane√ßa no contexto de cobran√ßas"""
        
        # Se a mensagem do usu√°rio n√£o for sobre cobran√ßa, redireciona
        if not self.is_billing_related(user_message):
            return self.get_out_of_scope_response()
        
        # Se a resposta proposta n√£o for sobre cobran√ßa, ajusta
        if not self.is_billing_related(proposed_response):
            return f"{proposed_response} Mas voltando ao que importa - sobre sua cobran√ßa, como posso ajudar?"
        
        return proposed_response
        
    def record_interaction(self, user_message: str, bot_response: str, 
                         user_satisfaction: Optional[float] = None):
        """Registra intera√ß√£o para aprendizado"""
        interaction = {
            "timestamp": datetime.now(),
            "user_message": user_message,
            "bot_response": bot_response,
            "satisfaction": user_satisfaction
        }
        
        message_hash = hash(user_message.lower().strip())
        self.interaction_patterns[message_hash].append(interaction)
        
        if user_satisfaction is not None:
            self.success_metrics[message_hash] = user_satisfaction
    
    def get_improved_response(self, user_message: str) -> Optional[str]:
        """Obt√©m resposta melhorada baseada no aprendizado"""
        message_hash = hash(user_message.lower().strip())
        
        if message_hash in self.interaction_patterns:
            interactions = self.interaction_patterns[message_hash]
            # Retorna a resposta com maior satisfa√ß√£o
            best_interaction = max(interactions, 
                                 key=lambda x: x.get("satisfaction", 0.0))
            if best_interaction.get("satisfaction", 0) > 0.7:
                return best_interaction["bot_response"]
        
        return None

# Classe IntentClassifier s√≥ √© criada se PyTorch estiver dispon√≠vel
if TORCH_AVAILABLE:
    class IntentClassifier(torch.nn.Module):
        """Classificador de inten√ß√µes usando BERT"""
        
        def __init__(self, num_intents: int, hidden_size: int = 768, dropout: float = 0.3):
            super().__init__()
            if TRANSFORMERS_AVAILABLE:
                self.bert = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')
                self.dropout = torch.nn.Dropout(dropout)
                self.classifier = torch.nn.Linear(hidden_size, num_intents)
            else:
                self.bert = None
                self.dropout = None
                self.classifier = None
            
        def forward(self, input_ids, attention_mask):
            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
            pooled_output = outputs.pooler_output
            output = self.dropout(pooled_output)
            return self.classifier(output)
else:
    # Fallback quando PyTorch n√£o est√° dispon√≠vel
    class IntentClassifier:
        """Classificador de inten√ß√µes simples (fallback sem PyTorch)"""
        
        def __init__(self, *args, **kwargs):
            self.available = False
            
        def forward(self, *args, **kwargs):
            return None

class BillingChatBot:
    """ü§ñ CLAUDIA DA DESK - BOT CONVERSACIONAL SUPREMO üöÄ
    Sistema de IA de √öltima Gera√ß√£o com:
    - Intelig√™ncia Emocional Avan√ßada
    - Mem√≥ria Conversacional Profunda  
    - Compreens√£o Sem√¢ntica Suprema
    - Personalidade Emp√°tica e Natural
    - FOCO EXCLUSIVO EM COBRAN√áAS E FATURAS
    """
    
    def __init__(self):
        self.config = active_config
        self.device = torch.device(self.config.MODEL_DEVICE) if TORCH_AVAILABLE else None
        
        # üß† CONFIGURA√á√ïES SUPREMAS DO MODELO
        self.max_length = self.config.MODEL_MAX_LENGTH
        self.temperature = self.config.MODEL_TEMPERATURE
        
        # üî§ TOKENIZER AVAN√áADO PARA PORTUGU√äS
        if TRANSFORMERS_AVAILABLE:
            self.tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')
        else:
            self.tokenizer = None
        
        # üåü SISTEMAS DE IA SUPREMOS - AGORA COM FOCO EM COBRAN√áAS
        self.text_normalizer = BrazilianTextNormalizer()
        self.emotional_intelligence = EmotionalIntelligence()
        self.memory_system = AdvancedMemorySystem()
        self.spell_corrector = SpellCorrector()
        self.billing_nlp = AdvancedBillingNLP()
        self.billing_enforcer = BillingContextEnforcer()
        self.context_enforcer = BillingContextEnforcer()
        
        # üéØ INTENTS E RESPOSTAS EXPANDIDOS - EXCLUSIVO COBRAN√áAS
        self.intents = self._load_advanced_intents()
        self.responses = self._load_claudia_responses()
        self.emotional_responses = self._load_emotional_responses()
        
        # üßÆ MODELOS NEURAIS
        self.intent_model = None
        self.intent_labels = list(self.intents.keys())
        
        # üöÄ CARREGAMENTO AVAN√áADO
        self._load_or_initialize_model()
        self.patterns = self._compile_advanced_patterns()
        
        # üíæ SISTEMA DE APRENDIZADO CONT√çNUO
        self.conversation_learning = ConversationLearning()
        
        app_logger.info("ü§ñ CLAUDIA SUPREMA INICIALIZADA", {
            "emotional_intelligence": True,
            "memory_system": True,
            "advanced_nlp": True,
            "billing_focus": True,
            "context_enforcement": True,
            "device": str(self.device)
        })
        
    def _load_advanced_intents(self) -> Dict[str, List[str]]:
        """Carrega intents expandidos EXCLUSIVOS para cobran√ßas e faturas"""
        return {
            "saudacao": [
                # Formal
                "oi", "ol√°", "bom dia", "boa tarde", "boa noite", "oi tudo bem",
                # Coloquial e abreviado
                "oi", "ola", "oie", "oii", "oiii", "e ai", "eae", "fala", "fala ai",
                "bd", "bt", "bn", "blz", "beleza", "tudo bem", "td bem", "suave",
                "salve", "opa", "opa blz", "ei", "hey", "al√¥", "alo",
                # Com erros de digita√ß√£o
                "bom fis", "boa tards", "tudo bm", "td bm", "tlg", "tmj"
            ],
            "confirmacao_pagamento": [
                # Formal - Pagamentos
                "j√° paguei", "pagamento feito", "paguei", "fiz o pagamento", "quitei",
                "j√° foi pago", "transferi", "fiz a transfer√™ncia", "pix feito",
                "pago via boleto", "compensado", "liquidei", "quitei a d√≠vida",
                # Coloquial/abreviado
                "ja paguei", "paguei ja", "ja pago", "ja foi", "ja ta pago",
                "fiz pix", "mandei pix", "transferi ja", "ja transferi",
                "paguei ontem", "paguei hj", "paguei hoje", "paguei boleto",
                "compensei", "paguei a fatura", "paguei conta", "quitei divida",
                # Com erros
                "ja pagei", "paguie", "ja pagiei", "fis pagamento", "quitei ja",
                "pixi feito", "fis pix", "transferi onti", "baguei",
                # G√≠rias
                "ja foi esse role", "ja resolvi", "ja era", "mandei a grana",
                "ja mandei", "ja enviei", "ja depositei", "quitei", "paguei tudo"
            ],
            "negociacao": [
                # Formal - Negocia√ß√£o de d√≠vidas
                "posso parcelar", "parcelamento", "desconto", "n√£o posso pagar",
                "dificuldades", "negociar", "prazo", "condi√ß√µes", "renegociar",
                "acordo", "acordo de pagamento", "proposta", "entrada",
                # Coloquial
                "da pra parcelar", "parcela ai", "divide ai", "nao consigo pagar",
                "nao to conseguindo", "ta dificil", "ta apertado", "sem grana",
                "quebrado", "duro", "liso", "zerado", "sem dinheiro", "sem condi√ß√µes",
                "vamo negociar", "da um desconto", "abaixa ai", "faz um preco",
                "parcela minha divida", "entra em acordo", "faz um acordo",
                # Com erros
                "parcelar", "nao consigo", "difficuldades", "negosiar",
                "descontinho", "abaicha", "ta difisil", "sem dinherio",
                # Express√µes populares
                "to sem condi√ß√µes", "to liso", "to quebrado", "sem bufunfa",
                "desempregado", "sem trampo", "perdeu emprego", "demitido",
                "nao recebi", "salario atrasado", "esperando pagamento"
            ],
            "informacoes": [
                # Formal - Informa√ß√µes de cobran√ßa
                "qual valor", "quanto devo", "data vencimento", "dados pagamento",
                "como pagar", "n√∫mero conta", "pix", "dados banc√°rios", "boleto",
                "linha digitavel", "codigo barras", "vencimento", "valor original",
                "valor atualizado", "juros", "multa", "atraso", "saldo devedor",
                # Coloquial
                "quanto √©", "quanto ta", "qnto", "valor", "preco", "quanto falta",
                "como que paga", "onde pago", "chave pix", "conta", "boleto",
                "dados", "info", "informa√ß√£o", "detalhes", "situacao", "status",
                # Com erros
                "qunto", "qnto devo", "infoma√ß√£o", "detos", "pixe",
                "conta bancariya", "como q pago", "ond pago", "boletu"
            ],
            "contestacao": [
                # Formal - Contesta√ß√£o de cobran√ßa
                "n√£o devo", "erro", "n√£o reconhe√ßo", "contestar", "disputa",
                "duplicata", "cobran√ßa indevida", "valor errado", "duvida da compra",
                "nao fiz essa compra", "nao autorizei", "fraude", "clonaram meu cartao",
                # Coloquial
                "nao devo nada", "isso ta errado", "nunca comprei", "nao fiz compra",
                "nao eh meu", "nao fui eu", "engano", "erro ai", "cobranca errada",
                "ta errado isso", "nao conhe√ßo", "quem eh voces", "golpe", "fraude",
                "nao autorizei pagamento", "nao reconheco essa compra",
                # Com raiva/frustra√ß√£o
                "que isso", "que historia eh essa", "golpe", "nao caio",
                "para de ligar", "nao quero", "deixa eu em paz", "ass√©dio",
                # Com erros
                "nao dvo", "tah errado", "nunka comprei", "nao foi eu", "nao autorizei"
            ],
            "agendamento": [
                # Formal - Agendamento de pagamento
                "pagar amanh√£", "semana que vem", "pr√≥xima semana", "agendar",
                "data para pagar", "quando posso pagar", "prazo", "vencimento",
                "recebo dia", "data do pagamento", "marcar pagamento",
                # Coloquial
                "pago amanha", "pago semana q vem", "semana q vem", "na sexta",
                "no sabado", "segunda feira", "depois do pagamento", "quando cair",
                "recebo dia 5", "quando receber", "fim do mes", "quando der",
                "no outro mes", "daqui uma semana", "daqui 15 dias",
                # Com erros
                "pago amanha", "seman q vem", "seista feira", "sesta",
                "depos", "fim do mex", "quano receber", "daqui huma semana"
            ],
            "despedida": [
                # Formal
                "tchau", "at√© logo", "obrigado", "valeu", "ok", "at√© breve",
                # Coloquial
                "vlw", "valew", "brigado", "obrigada", "obg", "obrigad√£o",
                "tmj", "falou", "flw", "ate mais", "ate logo", "at√©",
                "blz", "beleza", "suave", "de boa", "ok entendi", "ta certo",
                # Com erros
                "brigadu", "vlws", "falow", "ati mais", "obriqado", "at√© logu"
            ],
            "pedido_ajuda": [
                # Formal - Ajuda com cobran√ßa
                "help", "ajuda", "n√£o entendi", "como funciona", "d√∫vida",
                "me ajuda", "nao entendi nada", "como assim", "explica ai",
                "nao to entendendo", "confuso", "perdido", "como que eh",
                "o que significa", "nao sei", "ensina ai", "como faz",
                # Com erros
                "nao intendi", "ajuda ai", "como asim", "esplica",
                "nao to intendendo", "perdidu", "nao seii"
            ],
            "ansiedade_cobranca": [
                # Express√µes de ansiedade/preocupa√ß√£o sobre cobran√ßa
                "to preocupado", "to nervoso", "que vai acontecer",
                "vao me processar", "nome sujo", "spc", "serasa",
                "protesto", "negativado", "score baixo", "vai pra justi√ßa",
                "vao me executar", "vao penhorar", "vao tomar meu bem",
                "vai ficar no spc", "vai prejudicar meu nome", "consequencias",
                "multa", "juros", "encargos", "atraso", "vencimento"
            ],
            "situacao_financeira": [
                # Explica√ß√µes da situa√ß√£o financeira
                "perdi emprego", "desempregado", "sem trabalho", "doente",
                "internado", "hospital", "familia doente", "problemas pessoais",
                "separacao", "divorcio", "morte na familia", "salario reduzido",
                "empresa fechou", "sem renda", "contas atrasadas", "dividas"
            ],
            "status_conta": [
                # Status espec√≠fico de conta/cobran√ßa
                "status da conta", "minha conta", "situacao da divida", "saldo atual",
                "valor em aberto", "conta em atraso", "conta vencida", "quitacao",
                "baixa", "desconto", "abono", "perdao de divida"
            ],
            "comprovante": [
                # Comprovantes de pagamento
                "comprovante", "comprovante de pagamento", "recibo", "protocolo",
                "confirma√ß√£o", "comprovante pix", "comprovante boleto", "protocolo atendimento"
            ]
        }
    
    def _load_claudia_responses(self) -> Dict[str, List[str]]:
        """Respostas da Claudia - emp√°tica e profissional, mas acess√≠vel"""
        return {
            "saudacao": [
                "Oi! Eu sou a Claudia da Desk! üòä Como posso te ajudar hoje?",
                "Ol√°! Claudia aqui da Desk. Estou aqui pra resolver sua situa√ß√£o!",
                "E a√≠! Sou a Claudia da Desk. Vamos conversar sobre seu pagamento?",
                "Oi! Claudia da Desk falando. Como posso facilitar pra voc√™ hoje?"
            ],
            "confirmacao_pagamento": [
                "Que √≥timo! üéâ Vou verificar seu pagamento aqui no sistema. Obrigada por avisar!",
                "Perfeito! J√° anotei que voc√™ pagou. Vou confirmar tudo certinho pra voc√™! ‚úÖ",
                "Maravilha! Recebemos sim. S√≥ me d√° uns minutinhos pra confirmar no sistema, ok?",
                "Show! Pagamento confirmado. Voc√™ √© 10! Muito obrigada! üëè"
            ],
            "negociacao": [
                "Olha, eu te entendo perfeitamente! üíô Vamos achar uma solu√ß√£o boa pra voc√™.",
                "Sem estresse! A gente sempre d√° um jeito. Que tal conversarmos sobre as op√ß√µes?",
                "Imagino como deve estar dif√≠cil. Relaxa que vamos resolver isso juntos! ü§ù",
                "Entendo sua situa√ß√£o. Aqui na Desk a gente sempre encontra uma sa√≠da!"
            ],
            "informacoes": [
                "Claro! Vou te passar tudo certinho! üìã Qualquer d√∫vida me fala, ok?",
                "Sem problema! Deixa eu buscar suas informa√ß√µes aqui...",
                "Opa! Vou te explicar tudinho. √â s√≥ um momento que j√° te mando os dados!",
                "Pode deixar comigo! Vou te dar todas as informa√ß√µes que voc√™ precisa! üí¨"
            ],
            "contestacao": [
                "Nossa, que situa√ß√£o! üòÆ Vou verificar isso urgente pra voc√™, pode deixar!",
                "Eita! Vamos esclarecer isso j√°! Me d√° s√≥ um momento pra investigar...",
                "Que estranho mesmo! Deixa eu ver o que rolou aqui no sistema...",
                "Entendi sua preocupa√ß√£o. Vou apurar tudo direitinho pra gente resolver!"
            ],
            "agendamento": [
                "Tranquilo! üìÖ Vamos agendar numa data boa pra voc√™. Quando fica melhor?",
                "Sem problema! A gente agenda certinho. Qual dia voc√™ consegue?",
                "Perfeito! Vamos organizar isso. Me fala quando d√° pra voc√™!",
                "√ìtima ideia! Vamos marcar uma data que funcione no seu or√ßamento!"
            ],
            "despedida": [
                "Valeu! üëã Qualquer coisa me chama aqui que a Claudia resolve!",
                "At√© logo! Foi um prazer te ajudar! Claudia da Desk sempre √† disposi√ß√£o! üòä",
                "Tchau! Lembra que estou sempre aqui quando precisar, viu?",
                "Falou! Claudia da Desk se despede. At√© a pr√≥xima! üåü"
            ],
            "pedido_ajuda": [
                "Claro! Deixa a Claudia explicar tudinho pra voc√™! ü§ó",
                "Sem problema! Vou te explicar do jeitinho mais f√°cil!",
                "Opa! N√£o se preocupa, vou te ensinar passo a passo!",
                "Relaxa! A Claudia t√° aqui pra isso mesmo. Vamos l√°!"
            ],
            "ansiedade_cobranca": [
                "Ei, calma! üòå N√£o precisa ficar preocupado. Vamos resolver isso numa boa!",
                "Relaxa! Aqui na Desk a gente sempre d√° um jeito. Sem estresse!",
                "Fica tranquilo! Ningu√©m vai te prejudicar. Vamos conversar e resolver! üíô"
            ],
            "situacao_financeira": [
                "Nossa, que fase dif√≠cil! üòî Fica tranquilo que vamos encontrar uma sa√≠da juntos.",
                "Entendo perfeitamente sua situa√ß√£o. Vamos achar uma solu√ß√£o que caiba no seu bolso!",
                "Imagino como deve estar pesado pra voc√™. A gente vai dar um jeito! ü§ù"
            ],
            "default": [
                "Hmm, n√£o entendi muito bem... ü§î Pode me explicar de outro jeito?",
                "Opa! N√£o captei direito. Me fala de novo de uma forma diferente?",
                "Desculpa, n√£o consegui entender. Reformula a√≠ pra mim?",
                "Eita! N√£o peguei a informa√ß√£o. Tenta me explicar novamente?"
            ]
        }
    
    def _load_emotional_responses(self) -> Dict[str, Dict[str, List[str]]]:
        """Respostas da Claudia baseadas no estado emocional do usu√°rio"""
        return {
            "raiva": {
                "saudacao": [
                    "Oi! Percebo que voc√™ pode estar um pouco irritado... üòî Sou a Claudia da Desk, vamos resolver isso juntos!",
                    "Ol√°! Claudia aqui. Vejo que algo te incomodou, mas relaxa que vamos dar um jeito nisso! ü§ó"
                ],
                "geral": [
                    "Entendo sua irrita√ß√£o! üò§ Vamos resolver isso de uma vez por todas!",
                    "Sei que est√° chateado, e tem todo direito! Deixa a Claudia cuidar disso pra voc√™! üí™",
                    "Fica tranquilo! Quando a gente terminar aqui, voc√™ vai sair satisfeito! üéØ"
                ]
            },
            "tristeza": {
                "saudacao": [
                    "Oi... Sou a Claudia da Desk. Percebo que voc√™ pode estar passando por um momento dif√≠cil üòî Como posso ajudar?",
                    "Ol√°! Claudia aqui. Sei que √†s vezes as coisas ficam complicadas... Vamos conversar numa boa? üíô"
                ],
                "geral": [
                    "Imagino como deve estar sendo dif√≠cil pra voc√™... üòî Mas vamos achar uma solu√ß√£o juntos!",
                    "Entendo perfeitamente sua situa√ß√£o. A Claudia est√° aqui pra te apoiar! ü§ó",
                    "Sei que est√° pesado, mas voc√™ n√£o est√° sozinho nisso. Vamos resolver! üíô"
                ]
            },
            "alegria": {
                "saudacao": [
                    "Oi! Que energia boa! üòä Sou a Claudia da Desk! Como posso te ajudar hoje?",
                    "Ol√°! Claudia aqui! Adorei seu astral! Vamos resolver tudo rapidinho! ‚ú®"
                ],
                "geral": [
                    "Que bom ver voc√™ animado! üòä Isso facilita muito nossa conversa!",
                    "Sua energia positiva √© contagiante! Vamos manter esse clima bom! ‚≠ê",
                    "Adorei seu jeito! Com essa disposi√ß√£o, resolvemos tudo rapidinho! üöÄ"
                ]
            },
            "medo": {
                "saudacao": [
                    "Oi! Sou a Claudia da Desk. Fica tranquilo, aqui √© um ambiente seguro pra gente conversar üòå",
                    "Ol√°! Claudia aqui. N√£o precisa se preocupar, vamos esclarecer tudo devagar! ü§≤"
                ],
                "geral": [
                    "Relaxa! N√£o tem nada pra se preocupar. A Claudia vai cuidar de tudo! üòå",
                    "Fica tranquilo! Aqui na Desk a gente resolve tudo numa boa! üõ°Ô∏è",
                    "N√£o precisa ter medo! Vou te explicar tudo passo a passo! ü§ù"
                ]
            },
            "surpresa": {
                "saudacao": [
                    "Oi! Sou a Claudia da Desk! Alguma coisa te surpreendeu? Vamos esclarecer! üòÆ",
                    "Ol√°! Claudia aqui! Parece que voc√™ ficou surpreso com algo... Me conta! ü§î"
                ],
                "geral": [
                    "Nossa! Tamb√©m fiquei surpresa! Vamos entender isso juntos! üòÆ",
                    "Que situa√ß√£o mesmo! Deixa eu ver o que aconteceu... üïµÔ∏è‚Äç‚ôÄÔ∏è",
                    "Realmente √© surpreendente! Vamos investigar isso! üîç"
                ]
            },
            "frustra√ß√£o": {
                "saudacao": [
                    "Oi... Sou a Claudia da Desk. Sei que voc√™ deve estar cansado dessa situa√ß√£o üòî Vamos resolver!",
                    "Ol√°! Claudia aqui. Percebo sua frustra√ß√£o... Mas agora chegou a hora de resolver de vez! üí™"
                ],
                "geral": [
                    "Entendo sua frustra√ß√£o! Chega de enrola√ß√£o, vamos resolver isso AGORA! üéØ",
                    "Sei que voc√™ j√° tentou de tudo... Mas comigo vai ser diferente! üí´",
                    "Cansei junto com voc√™! Agora √© comigo, e eu n√£o desisto! üî•"
                ]
            }
        }
    
    def _compile_patterns(self) -> Dict[str, List]:
        """Compila padr√µes regex para detec√ß√£o r√°pida"""
        patterns = {}
        
        # Padr√µes para valores monet√°rios
        patterns["valor_money"] = [
            re.compile(r'R\$\s*(\d+(?:[.,]\d{2})?)', re.IGNORECASE),
            re.compile(r'(\d+)\s*reais?', re.IGNORECASE),
            re.compile(r'(\d+[.,]\d{2})', re.IGNORECASE)
        ]
        
        # Padr√µes para datas
        patterns["data"] = [
            re.compile(r'(\d{1,2})[\/\-](\d{1,2})[\/\-](\d{2,4})'),
            re.compile(r'(amanh√£|hoje|ontem)', re.IGNORECASE),
            re.compile(r'(segunda|ter√ßa|quarta|quinta|sexta|s√°bado|domingo)', re.IGNORECASE)
        ]
        
        # Padr√µes para confirma√ß√£o
        patterns["confirmacao"] = [
            re.compile(r'\b(sim|yes|ok|certo|correto|exato)\b', re.IGNORECASE),
            re.compile(r'\b(n√£o|no|nao|nope|errado)\b', re.IGNORECASE)
        ]
        
        return patterns
    
    def _load_or_initialize_model(self):
        """Carrega modelo existente ou inicializa novo"""
        try:
            model_path = self.config.MODEL_PATH
            if torch.cuda.is_available() and self.device.type == 'cuda':
                checkpoint = torch.load(model_path)
            else:
                checkpoint = torch.load(model_path, map_location='cpu')
            
            self.intent_model = IntentClassifier(len(self.intent_labels))
            self.intent_model.load_state_dict(checkpoint['model_state_dict'])
            self.intent_model.to(self.device)
            self.intent_model.eval()
            
            app_logger.info("CHATBOT_MODEL_LOADED", {"model_path": model_path})
            
        except Exception as e:
            app_logger.warning("CHATBOT_MODEL_LOAD_FAILED", {"error": str(e)})
            # Inicializa modelo vazio para treinamento futuro
            self.intent_model = IntentClassifier(len(self.intent_labels))
            self.intent_model.to(self.device)
    
    async def process_message(self, message: str, context: ConversationContext, user_id: str = None) -> Dict[str, Any]:
        """üöÄ PROCESSAMENTO SUPREMO DE MENSAGEM - N√çVEL CHATGPT++"""
        
        result = {
            "response": "",
            "intent": "default",
            "confidence": 0.0,
            "entities": {},
            "actions": [],
            "context_updates": {},
            "emotional_state": None,
            "semantic_understanding": None,
            "memory_context": None
        }
        
        try:
            # üß† AN√ÅLISE EMOCIONAL SUPREMA
            emotional_state = self.emotional_intelligence.analyze_emotion(message)
            result["emotional_state"] = emotional_state
            
            # üîí VERIFICA√á√ÉO DE ESCOPO - 100% COBRAN√áAS
            if not self.context_enforcer.is_billing_related(message):
                result["response"] = self.context_enforcer.get_out_of_scope_response()
                result["intent"] = "out_of_scope"
                result["confidence"] = 1.0
                return result
            
            # üíæ RECUPERA√á√ÉO DE MEM√ìRIA CONTEXTUAL
            user_id = user_id or context.user_id or "anonymous"
            memory_context = self.memory_system.get_contextual_information(user_id, message)
            result["memory_context"] = memory_context
            
            # üîß PR√â-PROCESSAMENTO SUPREMO
            clean_message = self._preprocess_message(message)
            
            # üéØ PROCESSAMENTO NLP AVAN√áADO PARA COBRAN√áAS
            billing_intent = self.billing_nlp.extract_billing_intent(clean_message)
            financial_entities = self.billing_nlp.extract_financial_entities(clean_message)
            financial_sentiment = self.billing_nlp.analyze_financial_sentiment(clean_message)
            
            # Atualiza resultados com informa√ß√µes financeiras
            result["financial_entities"] = financial_entities
            result["financial_sentiment"] = financial_sentiment
            
            # üìä ATUALIZA CONTEXTO DE COBRAN√áA
            try:
                from backend.models.conversation import conversation_manager
                import datetime as dt
                
                payment_method = None
                if 'payment_method' in financial_entities and financial_entities['payment_method']:
                    payment_method = financial_entities['payment_method'][0]
                
                due_date = None
                if 'due_date' in financial_entities and financial_entities['due_date']:
                    try:
                        due_date = dt.datetime.strptime(financial_entities['due_date'][0], '%Y-%m-%d')
                    except ValueError:
                        try:
                            due_date = dt.datetime.strptime(financial_entities['due_date'][0], '%d/%m/%Y')
                        except ValueError:
                            pass
                
                conversation_manager.update_billing_context(
                    user_id, 
                    financial_entities, 
                    billing_intent['intent'] if billing_intent['confidence'] > 0.7 else intent_result["intent"],
                    payment_method,
                    due_date
                )
            except ImportError:
                app_logger.warning("CONVERSATION_MANAGER_NOT_AVAILABLE", {"user_id": user_id})
            except Exception as e:
                app_logger.error("BILLING_CONTEXT_UPDATE_ERROR", e, {"user_id": user_id})
            
            # üéØ CLASSIFICA√á√ÉO DE INTENT INTELIGENTE
            intent_result = await self._classify_intent_supreme(clean_message, emotional_state, memory_context)
            
            # Prioriza inten√ß√µes de cobran√ßa se detectadas
            if billing_intent['confidence'] > 0.7:
                intent_result["intent"] = billing_intent['intent']
                intent_result["confidence"] = max(intent_result["confidence"], billing_intent['confidence'])
            
            result["intent"] = intent_result["intent"]
            result["confidence"] = intent_result["confidence"]
            
            # üìà TRACKING DE NEGOCIA√á√ÉO
            try:
                from backend.models.conversation import conversation_manager
                if intent_result["intent"] in ['negociacao', 'contestacao', 'situacao_financeira']:
                    conversation_manager.increment_negotiation_attempt(user_id)
            except ImportError:
                pass
            
            # üîç EXTRA√á√ÉO DE ENTIDADES AVAN√áADA
            result["entities"] = self._extract_entities_advanced(clean_message, emotional_state)
            result["entities"].update(financial_entities)
            
            # üßÆ COMPREENS√ÉO SEM√ÇNTICA
            semantic_understanding = self._analyze_semantic_understanding(
                clean_message, result["intent"], emotional_state, memory_context
            )
            result["semantic_understanding"] = semantic_understanding
            
            # üí¨ GERA√á√ÉO DE RESPOSTA SUPREMA
            response_data = await self._generate_supreme_response(
                message,
                clean_message,
                result["intent"],
                result["entities"],
                emotional_state,
                memory_context,
                context
            )
            
            result.update(response_data)
            
            # üîí GARANTIA FINAL DE CONTEXTO - 100% COBRAN√áAS
            result["response"] = self.context_enforcer.enforce_billing_context(
                message, result["response"]
            )
            
            # üìö ATUALIZA√á√ÉO DE MEM√ìRIA
            extracted_facts = self._extract_conversation_facts(message, result["response"], result["intent"])
            self.memory_system.update_memory(
                user_id, message, result["response"], emotional_state, extracted_facts
            )
            
            # üìä APRENDIZADO CONT√çNUO
            self.conversation_learning.record_interaction(message, result["response"])
            
            # üìù LOG SUPREMO
            conversation_logger.info("ü§ñ SUPREME_MESSAGE_PROCESSED", {
                "intent": result["intent"],
                "confidence": result["confidence"],
                "emotion": emotional_state.primary_emotion,
                "emotion_intensity": emotional_state.intensity,
                "entities_count": len(result["entities"]),
                "actions_count": len(result["actions"]),
                "semantic_score": semantic_understanding.intent_confidence if semantic_understanding else 0,
                "memory_facts": len(extracted_facts)
            })
            
        except Exception as e:
            app_logger.error("SUPREME_PROCESSING_ERROR", e, {
                "message_length": len(message),
                "user_id": user_id
            })
            result["response"] = "Ai, que problema! üòÖ A Claudia deu uma travadinha... Pode repetir pra mim?"
            result["intent"] = "error"
        
        return result
    
    def _preprocess_message(self, message: str) -> str:
        """Pr√©-processa mensagem com normaliza√ß√£o suprema"""
        # Primeiro, normaliza o texto coloquial brasileiro
        normalized = self.text_normalizer.normalize(message)
        
        # Corrige ortografia de palavras importantes
        words = normalized.split()
        corrected_words = []
        
        for word in words:
            corrected_word = self.spell_corrector.correct_word(word)
            corrected_words.append(corrected_word)
        
        final_text = ' '.join(corrected_words)
        
        # Log da transforma√ß√£o para debug
        if message.lower().strip() != final_text:
            app_logger.info("TEXT_NORMALIZATION", {
                "original": message,
                "normalized": final_text,
                "intent_signals": self.text_normalizer.extract_intent_signals(message)
            })
        
        return final_text
    
    async def _classify_intent_supreme(self, message: str, emotional_state: EmotionalState, memory_context: Dict[str, Any]) -> Dict[str, Any]:
        """üéØ CLASSIFICA√á√ÉO DE INTENT SUPREMA COM IA EMOCIONAL"""
        
        # Primeiro verifica aprendizado cont√≠nuo
        learned_response = self.conversation_learning.get_improved_response(message)
        if learned_response:
            # Extrai intent da resposta aprendida (simplificado)
            return {"intent": "learned_response", "confidence": 0.95}
        
        # Classifica√ß√£o tradicional melhorada
        rule_intent = self._classify_by_rules(message)
        
        # üß† BOOST EMOCIONAL - Ajusta intent baseado na emo√ß√£o
        emotional_boost = self._apply_emotional_intent_boost(rule_intent, emotional_state)
        
        # üíæ BOOST DE MEM√ìRIA - Ajusta baseado no hist√≥rico
        memory_boost = self._apply_memory_intent_boost(emotional_boost, memory_context)
        
        # Se modelo neural estiver dispon√≠vel, combina resultados
        if self.intent_model is not None:
            try:
                neural_intent = await self._classify_by_neural_model(message)
                
                # üî• ENSEMBLE SUPREMO - Combina todas as fontes
                final_intent = self._supreme_intent_ensemble(
                    rule_intent, neural_intent, memory_boost, emotional_state
                )
                return final_intent
                
            except Exception as e:
                app_logger.warning("NEURAL_CLASSIFICATION_FAILED", {"error": str(e)})
        
        return memory_boost
    
    def _apply_emotional_intent_boost(self, intent_result: Dict[str, Any], emotional_state: EmotionalState) -> Dict[str, Any]:
        """Aplica boost baseado no estado emocional"""
        intent = intent_result["intent"]
        confidence = intent_result["confidence"]
        emotion = emotional_state.primary_emotion
        intensity = emotional_state.intensity
        
        # Regras de boost emocional
        emotional_boosts = {
            "raiva": {
                "contestacao": 0.3,
                "negociacao": 0.2,
                "pedido_ajuda": 0.1
            },
            "tristeza": {
                "negociacao": 0.4,
                "situacao_financeira": 0.3,
                "pedido_ajuda": 0.2
            },
            "medo": {
                "ansiedade_cobranca": 0.4,
                "pedido_ajuda": 0.3,
                "informacoes": 0.2
            },
            "frustra√ß√£o": {
                "contestacao": 0.3,
                "negociacao": 0.2,
                "pedido_ajuda": 0.2
            }
        }
        
        if emotion in emotional_boosts and intent in emotional_boosts[emotion]:
            boost = emotional_boosts[emotion][intent] * intensity
            confidence = min(confidence + boost, 1.0)
        
        return {"intent": intent, "confidence": confidence}
    
    def _apply_memory_intent_boost(self, intent_result: Dict[str, Any], memory_context: Dict[str, Any]) -> Dict[str, Any]:
        """Aplica boost baseado na mem√≥ria conversacional"""
        intent = intent_result["intent"]
        confidence = intent_result["confidence"]
        
        # Se o usu√°rio j√° mostrou padr√£o de comportamento espec√≠fico
        emotional_pattern = memory_context.get("emotional_pattern", {})
        recent_emotions = emotional_pattern.get("recent_emotion", "neutro")
        
        # Boost baseado em padr√µes emocionais recentes
        pattern_boosts = {
            "raiva": {"contestacao": 0.2, "negociacao": 0.1},
            "tristeza": {"negociacao": 0.3, "situacao_financeira": 0.2},
            "frustra√ß√£o": {"contestacao": 0.2}
        }
        
        if recent_emotions in pattern_boosts and intent in pattern_boosts[recent_emotions]:
            boost = pattern_boosts[recent_emotions][intent]
            confidence = min(confidence + boost, 1.0)
        
        return {"intent": intent, "confidence": confidence}
    
    def _supreme_intent_ensemble(self, rule_intent: Dict, neural_intent: Dict, memory_intent: Dict, emotional_state: EmotionalState) -> Dict[str, Any]:
        """Combina todos os m√©todos de classifica√ß√£o"""
        
        # Pesos dos diferentes classificadores
        weights = {
            "rule": 0.4,
            "neural": 0.3,
            "memory": 0.2,
            "emotional": 0.1
        }
        
        # Se emo√ß√£o √© intensa, d√° mais peso ao contexto emocional
        if emotional_state.intensity > 0.7:
            weights["memory"] += 0.1
            weights["neural"] -= 0.1
        
        # Calcula score ponderado
        candidates = [
            (rule_intent["intent"], rule_intent["confidence"] * weights["rule"]),
            (neural_intent["intent"], neural_intent["confidence"] * weights["neural"]),
            (memory_intent["intent"], memory_intent["confidence"] * weights["memory"])
        ]
        
        # Escolhe o melhor
        best_intent, best_score = max(candidates, key=lambda x: x[1])
        
        return {"intent": best_intent, "confidence": min(best_score, 1.0)}
    
    def _extract_entities_advanced(self, message: str, emotional_state: EmotionalState) -> Dict[str, Any]:
        """Extra√ß√£o de entidades com consci√™ncia emocional"""
        entities = self._extract_entities(message)
        
        # Adiciona contexto emocional
        entities["emotional_intensity"] = emotional_state.intensity
        entities["emotional_indicators"] = emotional_state.indicators
        
        # Extrai entidades espec√≠ficas por emo√ß√£o
        if emotional_state.primary_emotion == "raiva":
            # Procura por alvos da raiva
            anger_targets = re.findall(r'(voc√™s|empresa|sistema|banco|atendimento)', message.lower())
            if anger_targets:
                entities["anger_target"] = anger_targets[0]
        
        elif emotional_state.primary_emotion == "tristeza":
            # Procura por motivos da tristeza
            sadness_reasons = re.findall(r'(desemprego|doente|fam√≠lia|perdeu|morreu)', message.lower())
            if sadness_reasons:
                entities["sadness_reason"] = sadness_reasons[0]
        
        return entities
    
    def _analyze_semantic_understanding(self, message: str, intent: str, emotional_state: EmotionalState, memory_context: Dict[str, Any]) -> SemanticUnderstanding:
        """An√°lise de compreens√£o sem√¢ntica avan√ßada"""
        
        # Calcula m√©tricas de compreens√£o
        intent_confidence = 0.8  # Placeholder - seria calculado com modelo sem√¢ntico
        
        # Similaridade sem√¢ntica com mensagens anteriores
        semantic_similarity = 0.7 if memory_context.get("conversation_count", 0) > 0 else 0.5
        
        # Relev√¢ncia contextual baseada na emo√ß√£o
        contextual_relevance = 0.9 if emotional_state.confidence > 0.7 else 0.6
        
        # Alinhamento emocional (se a resposta est√° adequada √† emo√ß√£o)
        emotional_alignment = 0.8 if emotional_state.primary_emotion != "neutro" else 0.5
        
        # Coer√™ncia do t√≥pico
        topic_coherence = 0.8  # Placeholder
        
        return SemanticUnderstanding(
            intent_confidence=intent_confidence,
            semantic_similarity=semantic_similarity,
            contextual_relevance=contextual_relevance,
            emotional_alignment=emotional_alignment,
            topic_coherence=topic_coherence
        )
    
    def _extract_conversation_facts(self, message: str, response: str, intent: str) -> Dict[str, Any]:
        """Extrai fatos importantes da conversa"""
        facts = {}
        
        # Extrai informa√ß√µes sobre situa√ß√£o financeira
        financial_keywords = ["desempregado", "sem trabalho", "doente", "hospital", "div√≥rcio"]
        for keyword in financial_keywords:
            if keyword in message.lower():
                facts["financial_situation"] = keyword
        
        # Extrai prefer√™ncias de pagamento
        payment_preferences = ["pix", "boleto", "cart√£o", "dinheiro"]
        for preference in payment_preferences:
            if preference in message.lower():
                facts["payment_preference"] = preference
        
        # Extrai hor√°rios preferenciais se mencionados
        time_patterns = re.findall(r'(\d{1,2}h|\d{1,2}:\d{2}|manh√£|tarde|noite)', message.lower())
        if time_patterns:
            facts["preferred_time"] = time_patterns[0]
        
        return facts
    
    async def _classify_intent(self, message: str) -> Dict[str, Any]:
        """Classifica intent da mensagem"""
        
        # Primeiro tenta classifica√ß√£o baseada em regras simples
        rule_intent = self._classify_by_rules(message)
        if rule_intent["confidence"] > 0.8:
            return rule_intent
        
        # Se modelo estiver dispon√≠vel, usa classifica√ß√£o neural
        if self.intent_model is not None:
            try:
                neural_intent = await self._classify_by_neural_model(message)
                
                # Combina resultados (ensemble)
                if neural_intent["confidence"] > rule_intent["confidence"]:
                    return neural_intent
                else:
                    return rule_intent
                    
            except Exception as e:
                app_logger.warning("NEURAL_CLASSIFICATION_FAILED", {"error": str(e)})
                return rule_intent
        
        return rule_intent
    
    def _classify_by_rules(self, message: str) -> Dict[str, Any]:
        """Classifica√ß√£o suprema baseada em regras e padr√µes brasileiros"""
        best_intent = "default"
        best_score = 0.0
        
        # Extrai sinais de inten√ß√£o primeiro
        intent_signals = self.text_normalizer.extract_intent_signals(message)
        
        # Se temos sinais claros, damos peso extra
        signal_boost = {
            "payment_confirmed": ("confirmacao_pagamento", 0.8),
            "wants_negotiation": ("negociacao", 0.7),
            "disputes_charge": ("contestacao", 0.9)
        }
        
        for signal in intent_signals:
            if signal in signal_boost:
                intent, confidence = signal_boost[signal]
                if confidence > best_score:
                    best_intent = intent
                    best_score = confidence
        
        # Classifica√ß√£o tradicional por palavras-chave (melhorada)
        for intent, examples in self.intents.items():
            score = 0.0
            matches = 0
            total_match_length = 0
            
            for example in examples:
                if example.lower() in message.lower():
                    matches += 1
                    match_length = len(example)
                    total_match_length += match_length
                    
                    # Pontua√ß√£o baseada na relev√¢ncia da palavra
                    if match_length > 3:  # Palavras mais longas s√£o mais espec√≠ficas
                        score += match_length * 1.5
                    else:
                        score += match_length
            
            # Normaliza score considerando o tamanho da mensagem e exemplos
            if matches > 0:
                # Score baseado na propor√ß√£o de matches e relev√¢ncia
                relevance_score = total_match_length / len(message) if len(message) > 0 else 0
                match_density = matches / len(examples) if len(examples) > 0 else 0
                
                normalized_score = min((relevance_score + match_density) / 2, 1.0)
                
                # Boost para intents mais espec√≠ficos
                if intent in ["confirmacao_pagamento", "contestacao", "ansiedade_cobranca"]:
                    normalized_score *= 1.2
                
                if normalized_score > best_score:
                    best_score = normalized_score
                    best_intent = intent
        
        # Ajuste final de confian√ßa
        confidence = min(best_score, 1.0)
        
        return {
            "intent": best_intent,
            "confidence": confidence
        }
    
    async def _classify_by_neural_model(self, message: str) -> Dict[str, Any]:
        """Classifica√ß√£o usando modelo neural"""
        try:
            # Tokeniza mensagem
            inputs = self.tokenizer(
                message,
                return_tensors="pt",
                max_length=self.max_length,
                truncation=True,
                padding=True
            )
            
            # Move para device apropriado
            input_ids = inputs["input_ids"].to(self.device)
            attention_mask = inputs["attention_mask"].to(self.device)
            
            # Faz predi√ß√£o
            with torch.no_grad():
                outputs = self.intent_model(input_ids, attention_mask)
                probabilities = torch.nn.functional.softmax(outputs, dim=-1)
                
                # Obt√©m melhor predi√ß√£o
                predicted_class = torch.argmax(probabilities, dim=-1).item()
                confidence = probabilities[0][predicted_class].item()
                
                intent = self.intent_labels[predicted_class]
                
                return {
                    "intent": intent,
                    "confidence": confidence
                }
                
        except Exception as e:
            app_logger.error("NEURAL_MODEL_PREDICTION_ERROR", e)
            return {"intent": "default", "confidence": 0.0}
    
    def _extract_entities(self, message: str) -> Dict[str, Any]:
        """Extrai entidades da mensagem"""
        entities = {}
        
        # Extrai valores monet√°rios
        for pattern in self.patterns["valor_money"]:
            matches = pattern.findall(message)
            if matches:
                entities["valor"] = matches[0]
        
        # Extrai datas
        for pattern in self.patterns["data"]:
            matches = pattern.findall(message)
            if matches:
                entities["data"] = matches[0]
        
        # Extrai confirma√ß√µes
        for pattern in self.patterns["confirmacao"]:
            matches = pattern.findall(message)
            if matches:
                entities["confirmacao"] = matches[0].lower()
        
        return entities
    
    async def _generate_contextual_response(
        self, 
        message: str, 
        intent: str, 
        entities: Dict[str, Any], 
        context: ConversationContext
    ) -> Dict[str, Any]:
        """Gera resposta contextual da Claudia - emp√°tica e profissional"""
        
        response_data = {
            "response": "",
            "actions": [],
            "context_updates": {}
        }
        
        # Seleciona template base da Claudia
        templates = self.responses.get(intent, self.responses["default"])
        base_response = np.random.choice(templates)
        
        # Personaliza√ß√£o especial da Claudia baseada no intent
        if intent == "saudacao":
            # Se √© primeira intera√ß√£o, se apresenta
            if not context.last_template_sent:
                response_data["response"] = base_response
            else:
                # Se j√° conversaram antes, √© mais informal
                claudia_followup = [
                    "Oi de novo! Claudia aqui! Como posso te ajudar agora? üòä",
                    "E a√≠! Claudia da Desk novamente! Em que posso ser √∫til?",
                    "Ol√°! A Claudia voltou! Vamos resolver mais alguma coisa?"
                ]
                response_data["response"] = np.random.choice(claudia_followup)
            
        elif intent == "confirmacao_pagamento":
            # Claudia fica empolgada com confirma√ß√£o
            if "pix" in message.lower():
                response_data["response"] = "Que √≥timo! üéâ PIX √© rapidinho! Vou verificar aqui no sistema. J√° apareceu na conta da Desk!"
            elif "boleto" in message.lower():
                response_data["response"] = "Perfeito! Boleto confirmado! üìã J√° anotei aqui. Voc√™ √© super organizado!"
            else:
                response_data["response"] = base_response
            
            response_data["actions"].append("verificar_pagamento")
            response_data["context_updates"]["payment_status"] = "verification_pending"
            
        elif intent == "negociacao":
            # Claudia √© super emp√°tica com dificuldades
            empathy_phrases = [
                "Imagino como deve estar complicado pra voc√™! üòî",
                "Entendo perfeitamente sua situa√ß√£o! üíô",
                "Nossa, que fase dif√≠cil mesmo! ",
                "Fico imaginando como deve estar pesado! "
            ]
            
            empathy = np.random.choice(empathy_phrases)
            
            if context.client_amount:
                amount_str = f"R$ {context.client_amount:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
                response_data["response"] = f"{empathy}{base_response}\n\nüí° Para os {amount_str}, olha as op√ß√µes que tenho:\n\nüîπ Parcelamento em at√© 6x sem juros\nüîπ 15% de desconto √† vista\nüîπ Prazo extra de 45 dias\n\nQual funciona melhor pra voc√™?"
            else:
                response_data["response"] = f"{empathy}{base_response}"
            
            response_data["actions"].append("oferecer_negociacao")
            response_data["context_updates"]["payment_status"] = "negotiating"
            
        elif intent == "informacoes":
            if context.client_amount:
                amount_str = f"R$ {context.client_amount:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
                response_data["response"] = f"{base_response}\n\nüí∞ Seu valor em aberto: {amount_str}\n\nüì± Formas de pagamento:\n‚Ä¢ PIX: desk.cobranca@pix.com\n‚Ä¢ Transfer√™ncia: Banco 001 Ag. 1234 CC. 56789-0\n‚Ä¢ Boleto: Posso gerar um novo se precisar!\n\nQual voc√™ prefere? A Claudia te ajuda! üòä"
            else:
                response_data["response"] = base_response + "\n\nüì± PIX: desk.cobranca@pix.com\nüè¶ Dados banc√°rios dispon√≠veis\nüìÑ Boleto sempre dispon√≠vel!"
            
            response_data["actions"].append("enviar_informacoes_pagamento")
            
        elif intent == "contestacao":
            # Claudia fica preocupada mas quer resolver
            concern_responses = [
                "Nossa, que situa√ß√£o! üòÆ Vou investigar isso urgente pra voc√™!",
                "Eita! Que estranho mesmo! Deixa eu ver o que rolou...",
                "Nossa! Isso n√£o pode estar certo! Vou apurar tudo agora!"
            ]
            concern = np.random.choice(concern_responses)
            
            response_data["response"] = f"{concern}\n\nVou transferir voc√™ para meu supervisor resolver isso pessoalmente. Ningu√©m vai te cobrar algo que n√£o deve!"
            response_data["actions"].append("escalate_to_human")
            response_data["context_updates"]["payment_status"] = "disputed"
            
        elif intent == "agendamento":
            response_data["response"] = base_response
            if "data" in entities:
                response_data["response"] += f"\n\nEnt√£o fica marcado para {entities['data']}! Vou anotar aqui na agenda da Desk! üìÖ"
            else:
                response_data["response"] += "\n\nMe fala que dia fica bom pra voc√™ que eu anoto tudo certinho!"
            response_data["actions"].append("agendar_pagamento")
            
        elif intent == "ansiedade_cobranca":
            # Claudia acalma a pessoa
            calming_responses = [
                "Ei, fica tranquilo! üòå Ningu√©m vai te prejudicar. A Desk s√≥ quer resolver numa boa!",
                "Relaxa! Aqui n√£o tem pegadinha. Vamos achar uma solu√ß√£o boa pra voc√™! üíô",
                "Calma! N√£o precisa ficar preocupado. A gente sempre d√° um jeito! ü§ó"
            ]
            response_data["response"] = np.random.choice(calming_responses)
            
        elif intent == "situacao_financeira":
            # Claudia √© muito emp√°tica
            empathy_responses = [
                "Nossa, que fase complicada! üòî Fica tranquilo que vamos encontrar uma sa√≠da juntos!",
                "Imagino como deve estar dif√≠cil pra voc√™! A Desk entende e vai te ajudar! üíô",
                "Que situa√ß√£o pesada! Mas relaxa, vamos resolver isso de um jeito que funcione pra voc√™! ü§ù"
            ]
            response_data["response"] = np.random.choice(empathy_responses)
            response_data["actions"].append("oferecer_negociacao_especial")
            
        else:
            # Para outros intents, usa resposta padr√£o
            response_data["response"] = base_response
        
        # Personaliza√ß√£o com nome do cliente
        if context.client_name:
            name = context.client_name.split()[0]  # S√≥ primeiro nome
            # Substitui "voc√™" por nome quando apropriado
            if intent in ["saudacao", "informacoes", "negociacao"]:
                response_data["response"] = response_data["response"].replace(
                    "te ajudar", f"te ajudar, {name}"
                ).replace(
                    "pra voc√™", f"pra voc√™, {name}"
                )
        
        return response_data
    
    async def _generate_supreme_response(
        self,
        original_message: str,
        clean_message: str,
        intent: str,
        entities: Dict[str, Any],
        emotional_state: EmotionalState,
        memory_context: Dict[str, Any],
        context: ConversationContext
    ) -> Dict[str, Any]:
        """üöÄ GERA√á√ÉO ULTRA-SUPREMA - N√çVEL GPT-4++ ü§ñ‚ú®"""
        
        response_data = {
            "response": "",
            "actions": [],
            "context_updates": {}
        }
        
        # üß† AN√ÅLISE CONTEXTUAL ULTRA-PROFUNDA
        conversation_depth = memory_context.get("conversation_count", 0)
        user_patterns = memory_context.get("behavioral_patterns", {})
        previous_intents = memory_context.get("intent_history", [])
        
        # üéØ INTELIG√äNCIA CONVERSACIONAL GPT-4
        ultra_context = {
            "conversation_flow": self._analyze_conversation_flow(previous_intents, intent),
            "user_personality": self._detect_user_personality(user_patterns),
            "situational_context": self._analyze_situational_context(entities, emotional_state),
            "temporal_context": self._analyze_temporal_context(memory_context),
            "relationship_depth": conversation_depth
        }
        
        # üé≠ EMO√á√ÉO ULTRA-NATURAL COM NUANCE HUMANA
        emotion = emotional_state.primary_emotion
        emotion_intensity = emotional_state.intensity
        
        # üåü GERA√á√ÉO DIN√ÇMICA DE PERSONALIDADE
        claudia_personality = self._generate_claudia_personality(ultra_context, emotion)
        
        # üéØ RESPOSTAS ULTRA-CONTEXTUAIS
        if conversation_depth == 0:
            # Primeira intera√ß√£o - acolhedora e profissional
            base_response = self._generate_first_interaction_response(intent, emotion, ultra_context)
        elif conversation_depth <= 3:
            # Intera√ß√µes iniciais - construindo confian√ßa
            base_response = self._generate_early_interaction_response(intent, emotion, ultra_context)
        else:
            # Relacionamento estabelecido - ultra personalizado
            base_response = self._generate_established_relationship_response(intent, emotion, ultra_context)
        
        # üß† PERSONALIZA√á√ÉO ULTRA-SUPREMA
        base_response = self._ultra_personalize_response(base_response, ultra_context, context, memory_context)
        
        # üí´ GERA√á√ÉO CONTEXTUAL ULTRA-SOFISTICADA
        response_data["response"] = await self._generate_ultra_contextual_response(
            base_response, intent, entities, emotional_state, ultra_context, context
        )
        
        # üéØ A√á√ïES ULTRA-INTELIGENTES
        response_data["actions"] = self._generate_ultra_smart_actions(
            intent, emotional_state, ultra_context, entities, context
        )
        
        # üìä ATUALIZA√á√ïES DE CONTEXTO ULTRA-AVAN√áADAS
        response_data["context_updates"] = self._generate_ultra_context_updates(
            intent, emotional_state, entities, ultra_context, context
        )
        
        # üé® ENRIQUECIMENTO FINAL ULTRA-NATURAL
        response_data["response"] = self._apply_ultra_natural_language(
            response_data["response"], ultra_context, emotional_state
        )
        
        return response_data
    
    def _analyze_conversation_flow(self, previous_intents: List[str], current_intent: str) -> Dict[str, Any]:
        """Analisa o fluxo da conversa para contexto ultra-natural"""
        flow_analysis = {
            "is_follow_up": len(previous_intents) > 0,
            "topic_changes": self._count_topic_changes(previous_intents, current_intent),
            "escalation_level": self._calculate_escalation_level(previous_intents),
            "resolution_progress": self._calculate_resolution_progress(previous_intents),
            "user_engagement": self._calculate_user_engagement(previous_intents)
        }
        return flow_analysis
    
    def _detect_user_personality(self, patterns: Dict[str, Any]) -> str:
        """Detecta personalidade do usu√°rio para respostas personalizadas"""
        if not patterns:
            return "unknown"
        
        traits = []
        if patterns.get("formality_score", 0) > 0.7:
            traits.append("formal")
        elif patterns.get("formality_score", 0) < 0.3:
            traits.append("casual")
        
        if patterns.get("emotional_responsiveness", 0) > 0.6:
            traits.append("emotional")
        else:
            traits.append("rational")
        
        if patterns.get("urgency_indicators", 0) > 0.5:
            traits.append("urgent")
        
        return "_".join(traits) if traits else "balanced"
    
    def _generate_claudia_personality(self, context: Dict[str, Any], emotion: str) -> Dict[str, str]:
        """Gera varia√ß√µes da personalidade da Claudia baseadas no contexto"""
        personalities = {
            "first_interaction": {
                "tone": "acolhedora_profissional",
                "language": "formal_educado",
                "empathy": "alta",
                "proactivity": "moderada"
            },
            "casual_user": {
                "tone": "amigavel_descontraida",
                "language": "coloquial_respeitosa",
                "empathy": "muito_alta",
                "proactivity": "alta"
            },
            "formal_user": {
                "tone": "profissional_respeitosa",
                "language": "formal_precisa",
                "empathy": "profissional",
                "proactivity": "moderada"
            },
            "emotional_user": {
                "tone": "empatica_acolhedora",
                "language": "calorosa_apoiante",
                "empathy": "extrema",
                "proactivity": "muito_alta"
            },
            "urgent_user": {
                "tone": "eficiente_direta",
                "language": "clara_objetiva",
                "empathy": "pr√°tica",
                "proactivity": "m√°xima"
            }
        }
        
        user_type = context.get("user_personality", "balanced")
        return personalities.get(user_type, personalities["first_interaction"])
    
    def _generate_first_interaction_response(self, intent: str, emotion: str, context: Dict[str, Any]) -> str:
        """Gera resposta para primeira intera√ß√£o ultra-acolhedora"""
        responses = {
            "saudacao": "Oi! Que prazer te conhecer! üòä Sou a Claudia, especialista em cobran√ßas da Desk, e estou aqui pra te ajudar com MUITO carinho e paci√™ncia!",
            "informacoes": "Ol√°! Seja muito bem-vindo(a)! üíô Vejo que est√° buscando informa√ß√µes - vou te explicar tudo com calma e clareza, t√° bom?",
            "negociacao": "Oi! Que bom que voc√™ chegou at√© aqui! üí™ Sei que situa√ß√µes financeiras podem ser desafiadoras, e estou aqui pra encontrar a melhor solu√ß√£o juntos!",
            "contestacao": "Ol√°! Entendo perfeitamente sua preocupa√ß√£o! üòü Vamos resolver isso com total transpar√™ncia e cuidado - sua paz de esp√≠rito √© minha prioridade!",
            "confirmacao_pagamento": "Oi! Muito obrigada pelo seu pagamento! üôè Sua responsabilidade √© admir√°vel - vou verificar tudo pra voc√™ agora mesmo!",
            "agendamento": "Ol√°! Que √≥timo que est√° pensando em organizar seu pagamento! üìÖ Vamos achar a data perfeita que funcione pra voc√™!"
        }
        return responses.get(intent, "Oi! Muito prazer! üòä Como posso te ajudar hoje?")
    
    def _generate_early_interaction_response(self, intent: str, emotion: str, context: Dict[str, Any]) -> str:
        """Gera resposta para intera√ß√µes iniciais construindo confian√ßa"""
        responses = {
            "saudacao": "Oi de novo! Que bom te ver por aqui! üòä",
            "informacoes": "Deixa eu te ajudar com essas informa√ß√µes! üí°",
            "negociacao": "Vamos encontrar uma solu√ß√£o que funcione pra voc√™! ü§ù",
            "contestacao": "Vamos resolver isso juntos, sem estresse! üíô",
            "confirmacao_pagamento": "Perfeito! Vou confirmar seu pagamento! ‚úÖ",
            "agendamento": "Vamos marcar isso direitinho! üìÖ"
        }
        return responses.get(intent, "Oi! Como posso te ajudar agora?")
    
    def _generate_established_relationship_response(self, intent: str, emotion: str, context: Dict[str, Any]) -> str:
        """Gera resposta ultra-personalizada para relacionamento estabelecido"""
        # Ultra-personaliza√ß√£o baseada no hist√≥rico
        flow = context.get("conversation_flow", {})
        if flow.get("is_follow_up"):
            return "Continuando nossa conversa... üîÑ"
        
        responses = {
            "saudacao": "E a√≠! Como voc√™ est√°? Sempre um prazer! üòä",
            "informacoes": "J√° sei exatamente o que voc√™ precisa! üí°",
            "negociacao": "Vou preparar as melhores op√ß√µes pra voc√™! üéØ",
            "contestacao": "Vou resolver isso imediatamente! üöÄ",
            "confirmacao_pagamento": "Confirmado! Voc√™ √© 10! ‚≠ê",
            "agendamento": "Marcado! Vou lembrar pra voc√™! üìã"
        }
        return responses.get(intent, "Oi! Sempre um prazer te ajudar!")
    
    def _ultra_personalize_response(self, response: str, context: Dict[str, Any], conversation_context: ConversationContext, memory: Dict[str, Any]) -> str:
        """Personaliza√ß√£o ultra-avan√ßada baseada em m√∫ltiplos fatores"""
        # Nome personalizado
        if conversation_context.client_name:
            name = conversation_context.client_name.split()[0]
            # Evita repeti√ß√£o excessiva
            if name.lower() not in response.lower():
                response = response.replace("voc√™", f"voc√™, {name}")
        
        # Refer√™ncias contextuais ultra-naturais
        flow = context.get("conversation_flow", {})
        if flow.get("escalation_level", 0) > 2:
            response = "Entendo que est√° ficando frustrado... " + response
        
        # Adapta√ß√£o temporal
        current_time = datetime.now()
        if current_time.hour < 12:
            response = "Bom dia! " + response
        elif current_time.hour < 18:
            response = "Boa tarde! " + response
        else:
            response = "Boa noite! " + response
        
        return response
    
    async def _generate_ultra_contextual_response(
        self,
        base_response: str,
        intent: str,
        entities: Dict[str, Any],
        emotional_state: EmotionalState,
        ultra_context: Dict[str, Any],
        context: ConversationContext
    ) -> str:
        """Gera resposta ultra-contextual com profundidade GPT-4"""
        response = base_response
        
        # üí∞ Contexto financeiro ultra-sofisticado
        if intent in ["informacoes", "negociacao"] and context.client_amount:
            amount_str = f"R$ {context.client_amount:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
            
            # An√°lise de contexto temporal
            days_overdue = 0
            if context.due_date:
                days_overdue = (datetime.now() - context.due_date).days
            
            if intent == "informacoes":
                if days_overdue > 30:
                    response += f"\n\nüí≥ Seu d√©bito de {amount_str} est√° com {days_overdue} dias de atraso."
                    response += "\nüìä Vou te mostrar exatamente como est√° composto:"
                    response += f"\n   ‚Ä¢ Valor original: {amount_str}"
                    if context.late_fee:
                        response += f"\n   ‚Ä¢ Juros/mora: R$ {context.late_fee:.2f}"
                    response += "\n\nüí° Posso te ajudar a regularizar isso de forma tranquila!"
                else:
                    response += f"\n\nüí∞ Seu valor atual √© {amount_str}"
                    response += "\n\nüéØ Op√ß√µes de pagamento dispon√≠veis:"
                    response += "\n   ‚Ä¢ PIX instant√¢neo: desk.cobranca@pix.com"
                    response += "\n   ‚Ä¢ Transfer√™ncia: Banco 001, Ag. 1234, CC. 56789-0"
                    response += "\n   ‚Ä¢ Boleto: Posso gerar um novo agora mesmo!"
                    
            elif intent == "negociacao":
                # Ofertas ultra-personalizadas
                if emotional_state.primary_emotion in ["tristeza", "medo"] and emotional_state.intensity > 0.6:
                    response += f"\n\nüíô {name}, vendo sua situa√ß√£o, preparei algo especial:"
                    response += f"\n   ‚Ä¢ Parcelamento em at√© 12x de R$ {context.client_amount/12:.2f}"
                    response += "\n   ‚Ä¢ 25% de desconto para pagamento √† vista"
                    response += "\n   ‚Ä¢ 90 dias para primeira parcela"
                    response += "\n   ‚Ä¢ Sem consulta ao SPC/Serasa"
                else:
                    response += f"\n\nüí° Para os {amount_str}, tenho √≥timas op√ß√µes:"
                    response += f"\n   ‚Ä¢ Parcelamento em at√© 8x de R$ {context.client_amount/8:.2f}"
                    response += "\n   ‚Ä¢ 20% de desconto para pagamento √† vista"
                    response += "\n   ‚Ä¢ 60 dias para primeira parcela"
        
        # üé≠ Adapta√ß√£o emocional ultra-nuanced
        if emotional_state.intensity > 0.5:
            if emotional_state.primary_emotion == "raiva":
                response += "\n\nüí™ Entendo perfeitamente sua frustra√ß√£o! Vou resolver isso AGORA SEM ENROLA√á√ÉO!"
                response += "\nüéØ Qual √© sua prioridade? Vou focar 100% nisso!"
            elif emotional_state.primary_emotion == "tristeza":
                response += "\n\nüíô Sinto muito que esteja passando por isso..."
                response += "\nü§ó Voc√™ n√£o est√° sozinho(a)! Estou aqui pra te apoiar em cada passo!"
                response += "\n‚ú® Vamos resolver isso juntos, sem press√£o e com carinho!"
            elif emotional_state.primary_emotion == "medo":
                response += "\n\nüõ°Ô∏è Fica tranquilo(a)! Aqui √© um ambiente 100% seguro!"
                response += "\nü§ù Nada de amea√ßas ou press√£o - s√≥ solu√ß√µes reais e vi√°veis!"
                response += "\nüíö Sua paz de esp√≠rito √© minha prioridade absoluta!"
        
        # üìö Refer√™ncias ultra-contextuais √† mem√≥ria
        recent_facts = memory_context.get("relevant_facts", {})
        if recent_facts:
            situation = recent_facts.get("financial_situation")
            if situation == "desempregado":
                response += "\n\nü§ù Sei que estar desempregado √© extremamente desafiador..."
                response += "\nüí™ Mas sua for√ßa em buscar solu√ß√µes j√° √© um grande primeiro passo!"
                response += "\nüéØ Vamos criar um plano que respeite sua realidade atual!"
            elif situation == "doente":
                response += "\n\nüíô Problemas de sa√∫de s√£o prioridade absoluta..."
                response += "\nüè• Sua sa√∫de vem primeiro - vamos resolver as pend√™ncias sem estresse!"
                response += "\nüïê Sem pressa, sem press√£o. Vamos no seu ritmo!"
        
        return response
    
    def _generate_ultra_smart_actions(self, intent: str, emotional_state: EmotionalState, context: Dict[str, Any], entities: Dict[str, Any], conversation_context: ConversationContext) -> List[str]:
        """Gera a√ß√µes ultra-inteligentes com previs√£o de necessidades"""
        actions = []
        
        # Previs√£o de necessidades baseada em padr√µes
        flow = context.get("conversation_flow", {})
        
        # A√ß√µes ultra-espec√≠ficas
        if intent == "confirmacao_pagamento":
            actions.extend([
                "verificar_pagamento_com_baixa_prioridade",
                "enviar_confirmacao_por_email",
                "atualizar_status_cliente_com_data",
                "preparar_recibo_digital"
            ])
        elif intent == "negociacao":
            actions.extend([
                "calcular_parcelas_personalizadas",
                "preparar_proposta_visual",
                "verificar_historico_pagamentos",
                "oferecer_desconto_contextual"
            ])
            
            if emotional_state.intensity > 0.7:
                actions.append("ativar_protocolo_empatico")
                actions.append("oferecer_acompanhamento_humano")
        
        # A√ß√µes preditivas
        if flow.get("escalation_level", 0) > 3:
            actions.append("preparar_intervencao_especialista")
        
        return actions
    
    def _generate_ultra_context_updates(self, intent: str, emotional_state: EmotionalState, entities: Dict[str, Any], context: Dict[str, Any], conversation_context: ConversationContext) -> Dict[str, Any]:
        """Gera atualiza√ß√µes de contexto ultra-sofisticadas"""
        updates = {}
        
        # An√°lise preditiva de comportamento
        flow = context.get("conversation_flow", {})
        
        # Atualiza√ß√µes ultra-espec√≠ficas
        if intent == "negociacao":
            updates.update({
                "payment_status": "ultra_negotiating",
                "negotiation_stage": self._calculate_negotiation_stage(flow),
                "predicted_outcome": self._predict_negotiation_outcome(emotional_state, entities),
                "next_best_action": self._calculate_next_best_action(intent, emotional_state)
            })
        
        # Rastreamento emocional avan√ßado
        updates.update({
            "emotional_trajectory": self._calculate_emotional_trajectory(emotional_state, context),
            "trust_level": self._calculate_trust_level(context),
            "satisfaction_prediction": self._predict_satisfaction(intent, emotional_state)
        })
        
        return updates
    
    def _apply_ultra_natural_language(self, response: str, context: Dict[str, Any], emotional_state: EmotionalState) -> str:
        """Aplica linguagem ultra-natural com varia√ß√µes humanas"""
        
        # Varia√ß√µes naturais de linguagem
        natural_variations = {
            "oi": ["Oi", "Ol√°", "E a√≠", "Oi, tudo bem?", "Oi! Como vai?"],
            "tchau": ["Tchau", "At√© logo", "Falou", "At√© mais", "Beijo!"],
            "obrigado": ["Obrigado", "Valeu", "Agrade√ßo muito", "Muito obrigado", "De cora√ß√£o!"]
        }
        
        # Adiciona emojis contextuais
        if emotional_state.primary_emotion == "alegria":
            response += " üòä‚ú®"
        elif emotional_state.primary_emotion == "tristeza":
            response += " üíô"
        elif emotional_state.primary_emotion == "raiva":
            response += " üí™"
        
        # Varia√ß√µes de pontua√ß√£o natural
        response = response.replace("!", np.random.choice(["!", "! üòä", "! üéØ"]))
        
        return response
    
    def _personalize_with_memory(self, response: str, memory_context: Dict[str, Any], context: ConversationContext) -> str:
        """Personaliza resposta com base na mem√≥ria"""
        
        # Adiciona nome se dispon√≠vel
        if context.client_name:
            name = context.client_name.split()[0]
            response = response.replace("voc√™", f"voc√™, {name}").replace("te ajudar", f"te ajudar, {name}")
        
        # Refer√™ncia a conversas anteriores
        conversation_count = memory_context.get("conversation_count", 0)
        if conversation_count > 1:
            if "sou a claudia" in response.lower():
                response = response.replace(
                    "Sou a Claudia da Desk", 
                    "√â a Claudia da Desk de novo"
                )
        
        # Adapta baseado no padr√£o emocional
        emotional_pattern = memory_context.get("emotional_pattern", {})
        if emotional_pattern.get("trend") == "declining":
            response = "Oi! Percebi que voc√™ tem passado por uns momentos dif√≠ceis... " + response
        elif emotional_pattern.get("trend") == "improving":
            response = "Oi! Que bom ver voc√™ mais animado! " + response
        
        return response
    
    def _count_topic_changes(self, previous_intents: List[str], current_intent: str) -> int:
        """Conta mudan√ßas de t√≥pico na conversa"""
        if not previous_intents:
            return 0
        
        topic_groups = {
            "financial": ["informacoes", "negociacao", "confirmacao_pagamento"],
            "emotional": ["contestacao", "negociacao"],
            "administrative": ["agendamento", "saudacao", "despedida"]
        }
        
        changes = 0
        current_group = None
        for group, intents in topic_groups.items():
            if current_intent in intents:
                current_group = group
                break
        
        for prev_intent in previous_intents[-3:]:
            prev_group = None
            for group, intents in topic_groups.items():
                if prev_intent in intents:
                    prev_group = group
                    break
            if prev_group != current_group:
                changes += 1
        
        return changes
    
    def _calculate_escalation_level(self, previous_intents: List[str]) -> int:
        """Calcula n√≠vel de escalada emocional"""
        if not previous_intents:
            return 0
        
        escalation_indicators = ["contestacao", "negociacao"]
        level = 0
        
        for intent in previous_intents[-5:]:
            if intent in escalation_indicators:
                level += 1
        
        return min(level, 5)
    
    def _calculate_resolution_progress(self, previous_intents: List[str]) -> float:
        """Calcula progresso de resolu√ß√£o"""
        if not previous_intents:
            return 0.0
        
        resolution_indicators = ["confirmacao_pagamento", "agendamento"]
        progress = sum(1 for intent in previous_intents[-10:] if intent in resolution_indicators)
        
        return min(progress * 0.2, 1.0)
    
    def _calculate_user_engagement(self, previous_intents: List[str]) -> float:
        """Calcula engajamento do usu√°rio"""
        if not previous_intents:
            return 0.5
        
        return min(len(previous_intents) * 0.1, 1.0)
    
    def _analyze_situational_context(self, entities: Dict[str, Any], emotional_state: EmotionalState) -> Dict[str, Any]:
        """Analisa contexto situacional"""
        return {
            "urgency_level": emotional_state.intensity,
            "financial_complexity": len(entities),
            "emotional_context": emotional_state.primary_emotion
        }
    
    def _analyze_temporal_context(self, memory_context: Dict[str, Any]) -> Dict[str, Any]:
        """Analisa contexto temporal"""
        return {
            "time_of_day": datetime.now().hour,
            "day_of_week": datetime.now().weekday(),
            "conversation_duration": memory_context.get("conversation_count", 0)
        }
    
    def _calculate_negotiation_stage(self, flow: Dict[str, Any]) -> str:
        """Calcula est√°gio da negocia√ß√£o"""
        escalation = flow.get("escalation_level", 0)
        if escalation == 0:
            return "inicial"
        elif escalation <= 2:
            return "desenvolvimento"
        elif escalation <= 4:
            return "avancado"
        else:
            return "critico"
    
    def _predict_negotiation_outcome(self, emotional_state: EmotionalState, entities: Dict[str, Any]) -> str:
        """Preve resultado da negocia√ß√£o"""
        if emotional_state.intensity > 0.8:
            return "necessita_intervencao"
        elif emotional_state.intensity > 0.5:
            return "provavel_acordo"
        else:
            return "alta_probabilidade"
    
    def _calculate_next_best_action(self, intent: str, emotional_state: EmotionalState) -> str:
        """Calcula pr√≥xima melhor a√ß√£o"""
        if emotional_state.intensity > 0.7:
            return "empatia_intensificada"
        elif intent == "negociacao":
            return "oferta_personalizada"
        else:
            return "continuar_conversa"
    
    def _calculate_emotional_trajectory(self, emotional_state: EmotionalState, context: Dict[str, Any]) -> str:
        """Calcula trajet√≥ria emocional"""
        return f"{emotional_state.primary_emotion}_{emotional_state.intensity:.2f}"
    
    def _calculate_trust_level(self, context: Dict[str, Any]) -> float:
        """Calcula n√≠vel de confian√ßa"""
        flow = context.get("conversation_flow", {})
        engagement = flow.get("user_engagement", 0)
        return min(engagement * 0.8 + 0.2, 1.0)
    
    def _predict_satisfaction(self, intent: str, emotional_state: EmotionalState) -> float:
        """Preve satisfa√ß√£o do usu√°rio"""
        base = 0.7
        if emotional_state.intensity < 0.3:
            base += 0.2
        elif emotional_state.intensity > 0.7:
            base -= 0.3
        
        return max(0, min(base, 1.0))
    
    async def _generate_contextual_supreme(
        self,
        base_response: str,
        intent: str,
        entities: Dict[str, Any],
        emotional_state: EmotionalState,
        memory_context: Dict[str, Any],
        context: ConversationContext
    ) -> str:
        """Gera resposta contextual suprema"""
        
        response = base_response
        
        # üí∞ INFORMA√á√ïES FINANCEIRAS INTELIGENTES
        if intent in ["informacoes", "negociacao"] and context.client_amount:
            amount_str = f"R$ {context.client_amount:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
            
            if intent == "informacoes":
                response += f"\n\nüí∞ Seu valor em aberto: {amount_str}"
                response += "\n\nüì± Formas de pagamento:"
                response += "\n‚Ä¢ PIX: desk.cobranca@pix.com"
                response += "\n‚Ä¢ Transfer√™ncia: Banco 001 Ag. 1234 CC. 56789-0"
                response += "\n‚Ä¢ Boleto: Posso gerar um novo se precisar!"
                
            elif intent == "negociacao":
                # Ofertas inteligentes baseadas na emo√ß√£o
                if emotional_state.primary_emotion in ["tristeza", "medo"]:
                    response += f"\n\nüíô Para os {amount_str}, tenho condi√ß√µes especiais:"
                    response += "\nüîπ Parcelamento em at√© 10x sem juros"
                    response += "\nüîπ 20% de desconto √† vista"
                    response += "\nüîπ Prazo extra de 60 dias"
                else:
                    response += f"\n\nüí° Para os {amount_str}, olha as op√ß√µes:"
                    response += "\nüîπ Parcelamento em at√© 6x sem juros"
                    response += "\nüîπ 15% de desconto √† vista"
                    response += "\nüîπ Prazo extra de 45 dias"
        
        # üé≠ ADAPTA√á√ÉO EMOCIONAL DIN√ÇMICA
        if emotional_state.intensity > 0.7:
            if emotional_state.primary_emotion == "raiva":
                response += "\n\nüí™ Vou resolver isso AGORA! Sem enrola√ß√£o!"
            elif emotional_state.primary_emotion == "tristeza":
                response += "\n\nüíô Voc√™ n√£o est√° sozinho nisso. Estou aqui pra te apoiar!"
            elif emotional_state.primary_emotion == "medo":
                response += "\n\nüõ°Ô∏è Fica tranquilo! Aqui √© ambiente seguro e vamos com calma!"
        
        # üìö REFER√äNCIAS √Ä MEM√ìRIA
        recent_facts = memory_context.get("relevant_facts", {})
        if "financial_situation" in recent_facts:
            situation = recent_facts["financial_situation"]
            if situation == "desempregado":
                response += "\n\nü§ù Sei que estar desempregado √© dif√≠cil. Vamos achar uma solu√ß√£o que funcione!"
            elif situation == "doente":
                response += "\n\nüíô Problemas de sa√∫de s√£o complicados mesmo. Vamos resolver isso sem press√£o!"
        
        return response
    
    def _generate_smart_actions(self, intent: str, emotional_state: EmotionalState, memory_context: Dict[str, Any], entities: Dict[str, Any]) -> List[str]:
        """Gera a√ß√µes inteligentes baseadas no contexto"""
        actions = []
        
        # A√ß√µes baseadas no intent
        if intent == "confirmacao_pagamento":
            actions.append("verificar_pagamento")
            actions.append("atualizar_status_cliente")
        elif intent == "negociacao":
            actions.append("oferecer_parcelamento")
            if emotional_state.intensity > 0.6:
                actions.append("oferecer_desconto_especial")
        elif intent == "contestacao":
            actions.append("escalate_to_human")
            actions.append("registrar_disputa")
        elif intent == "informacoes":
            actions.append("enviar_dados_pagamento")
        
        # A√ß√µes baseadas na emo√ß√£o
        if emotional_state.primary_emotion == "raiva" and emotional_state.intensity > 0.7:
            actions.append("priority_handling")
        elif emotional_state.primary_emotion == "tristeza":
            actions.append("empathetic_followup")
        elif emotional_state.primary_emotion == "medo":
            actions.append("reassurance_protocol")
        
        # A√ß√µes baseadas na mem√≥ria
        conversation_count = memory_context.get("conversation_count", 0)
        if conversation_count > 3:
            actions.append("check_satisfaction")
        
        return actions
    
    def _generate_context_updates(self, intent: str, emotional_state: EmotionalState, entities: Dict[str, Any], memory_context: Dict[str, Any]) -> Dict[str, Any]:
        """Gera atualiza√ß√µes de contexto avan√ßadas"""
        updates = {}
        
        # Atualiza√ß√µes baseadas no intent
        if intent == "confirmacao_pagamento":
            updates["payment_status"] = "verification_pending"
            updates["last_interaction_type"] = "payment_confirmation"
        elif intent == "negociacao":
            updates["payment_status"] = "negotiating"
            updates["negotiation_attempts"] = memory_context.get("negotiation_attempts", 0) + 1
        elif intent == "contestacao":
            updates["payment_status"] = "disputed"
            updates["escalation_required"] = True
        
        # Atualiza√ß√µes emocionais
        updates["last_emotion"] = emotional_state.primary_emotion
        updates["emotion_intensity"] = emotional_state.intensity
        
        # Prefer√™ncias detectadas
        if "payment_preference" in entities:
            updates["preferred_payment"] = entities["payment_preference"]
        
        return updates
    
    def get_model_info(self) -> Dict[str, Any]:
        """Retorna informa√ß√µes sobre o modelo"""
        return {
            "model_loaded": self.intent_model is not None,
            "device": str(self.device),
            "num_intents": len(self.intent_labels),
            "intents": self.intent_labels,
            "max_length": self.max_length,
            "temperature": self.temperature
        }
    
    def update_model_with_feedback(self, message: str, true_intent: str, predicted_intent: str):
        """Atualiza modelo com feedback do usu√°rio (para aprendizado cont√≠nuo)"""
        # Implementa√ß√£o simplificada - em produ√ß√£o seria mais sofisticada
        conversation_logger.info("MODEL_FEEDBACK_RECEIVED", {
            "message_hash": hash(message),
            "true_intent": true_intent,
            "predicted_intent": predicted_intent,
            "correct": true_intent == predicted_intent
        })
        
        # Aqui seria implementado o re-treinamento online
        # Por enquanto apenas registra para an√°lise posterior

# Inst√¢ncia global do bot
chatbot = BillingChatBot()
